{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Awn1jcNa0lLZ"
   },
   "source": [
    "# LangChain Integration Tutorial 🦜🔗\n",
    "\n",
    "**Let's get started on using Arize with LangChain!** ✨\n",
    "\n",
    "LangChain is a cutting-edge framework that facilitates the development of powerful applications driven by large language models. It follows two key principles: agenticity and data awareness. LangChain provides a wide range of modules that enable language models to connect with diverse data sources and interact seamlessly with their surroundings.\n",
    "\n",
    "Use Arize and LangChain together to effectively monitor the performance of your LLM agents, identify areas that require improvement, and make prompt engineering decisions about your LLM applications. With Arize and LangChain together, data scientists and machine learning engineers can ensure that their LLM applications are running at peak efficiency, enabling them to deliver improved results and drive greater value for their organizations.\n",
    "\n",
    "## Running This Notebook\n",
    "1. Step through each section below, pressing play on the code blocks to run the cells.\n",
    "2. Log in your browser to Arize App\n",
    "3. Copy and paste your Arize Space and API key"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "_X9GuXoSXleA"
   },
   "source": [
    "# Step 0. Install Dependencies, Import Libraries, Use GPU 📚\n",
    "\n",
    "Import LangChain, Arize, and Arize CallBack Handler for integration between two tools. \n",
    "\n",
    "⚠️ Use a GPU to save time generating embeddings. Click on 'Runtime', select 'Change Runtime Type' and\n",
    "select 'GPU'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -Uqq arize-otel==0.5.3 langchain==0.3.11 langchain-openai==0.2.12 \"openai>=1.26\" openinference-instrumentation-langchain==0.1.29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "from arize_otel import Endpoints, register_otel\n",
    "from langchain_openai import ChatOpenAI\n",
    "from openinference.instrumentation.langchain import LangChainInstrumentor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VMjE6vwOOKS-"
   },
   "source": [
    "# Step 1. Import and Setup Tracer\n",
    "\n",
    "The first step is to setup our tracer. After that, we will log the data from a LangChain driven application into Arize.\n",
    "\n",
    "Retrieve your Arize `API_KEY` and `SPACE_ID` from your Space Settings page, and paste them in the set-up section below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cTB9c-TVrZd"
   },
   "source": [
    "<img src=\"https://storage.googleapis.com/arize-assets/fixtures/copy-id-and-key.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPACE_ID = getpass(\"🔑 Enter your Arize Space ID: \")\n",
    "API_KEY = getpass(\"🔑 Enter your Arize API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure a Tracer\n",
    "\n",
    "We recommend using the `register_otel` helper method below to configure a tracer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"llm-langchain-demo\"\n",
    "\n",
    "register_otel(\n",
    "    endpoints=Endpoints.ARIZE,\n",
    "    space_id=SPACE_ID,\n",
    "    api_key=API_KEY,\n",
    "    model_id=MODEL_ID,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instrument LangChain calls in your application\n",
    "LangChainInstrumentor().instrument()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not openai_api_key:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"🔑 Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jjWMK3wo_FX"
   },
   "source": [
    "## Step 2: Define LLM\n",
    "\n",
    "Define the LLM with LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ec97f_LONfp3"
   },
   "source": [
    "## Step 3: Test LLM Responses and Logging into Arize\n",
    "Use some simple prompts to test if the LLM works properly and each prompt-response pair is logged into Arize with embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_queries = [\n",
    "    \"Tell me an interesting fact about pandas.\",\n",
    "    \"Explain the concept of overfitting in 2 sentences.\",\n",
    "]\n",
    "\n",
    "for query in lst_queries:\n",
    "    print(llm.invoke(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8DGWWhYOflGZ"
   },
   "source": [
    "## Step 4: Test LLM Chain and Agents with Arize Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"You are a playwright. Given the title of play, it is your job to write a synopsis for that title.\n",
    "Title: {title}\n",
    "Playwright: This is a synopsis for the above play:\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"title\"], template=template)\n",
    "synopsis_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "template = \"\"\"You are a play critic from the New York Times. Given the synopsis of play, it is your job to write a review for that play.\n",
    "Play Synopsis:\n",
    "{synopsis}\n",
    "Review from a New York Times play critic of the above play:\"\"\"\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"synopsis\"], template=template\n",
    ")\n",
    "review_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "overall_chain = SimpleSequentialChain(\n",
    "    chains=[synopsis_chain, review_chain],\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "test_prompts = [\n",
    "    {\n",
    "        \"input\": \"documentary about pandas who are about be extinct because of global warming\"\n",
    "    },\n",
    "    {\"input\": \"once upon a time in hollywood\"},\n",
    "    {\"input\": \"the best mo observability tooling\"},\n",
    "]\n",
    "\n",
    "overall_chain.invoke(test_prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "e4oRWiRTIGSb"
   },
   "source": [
    "### Overview\n",
    "Arize is an end-to-end ML observability and model monitoring platform. The platform is designed to help ML engineers and data science practitioners surface and fix issues with ML models in production faster with:\n",
    "- Automated ML monitoring and model monitoring\n",
    "- Workflows to troubleshoot model performance\n",
    "- Real-time visualizations for model performance monitoring, data quality monitoring, and drift monitoring\n",
    "- Model prediction cohort analysis\n",
    "- Pre-deployment model validation\n",
    "- Integrated model explainability\n",
    "\n",
    "### Website\n",
    "Visit Us At: https://arize.com/model-monitoring/\n",
    "\n",
    "### Additional Resources\n",
    "- [What is ML observability?](https://arize.com/what-is-ml-observability/)\n",
    "- [Playbook to model monitoring in production](https://arize.com/the-playbook-to-monitor-your-models-performance-in-production/)\n",
    "- [Using statistical distance metrics for ML monitoring and observability](https://arize.com/using-statistical-distance-metrics-for-machine-learning-observability/)\n",
    "- [ML infrastructure tools for data preparation](https://arize.com/ml-infrastructure-tools-for-data-preparation/)\n",
    "- [ML infrastructure tools for model building](https://arize.com/ml-infrastructure-tools-for-model-building/)\n",
    "- [ML infrastructure tools for production](https://arize.com/ml-infrastructure-tools-for-production-part-1/)\n",
    "- [ML infrastructure tools for model deployment and model serving](https://arize.com/ml-infrastructure-tools-for-production-part-2-model-deployment-and-serving/)\n",
    "- [ML infrastructure tools for ML monitoring and observability](https://arize.com/ml-infrastructure-tools-ml-observability/)\n",
    "\n",
    "Visit the [Arize Blog](https://arize.com/blog) and [Resource Center](https://arize.com/resource-hub/) for more resources on ML observability and model monitoring.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
