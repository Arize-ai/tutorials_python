{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Awn1jcNa0lLZ"
   },
   "source": [
    "# LangChain Integration Tutorial ü¶úüîó\n",
    "\n",
    "**Let's get started on using Arize with LangChain!** ‚ú®\n",
    "\n",
    "LangChain is a cutting-edge framework that facilitates the development of powerful applications driven by large language models. It follows two key principles: agenticity and data awareness. LangChain provides a wide range of modules that enable language models to connect with diverse data sources and interact seamlessly with their surroundings.\n",
    "\n",
    "Use Arize and LangChain together to effectively monitor the performance of your LLM agents, identify areas that require improvement, and make prompt engineering decisions about your LLM applications. With Arize and LangChain together, data scientists and machine learning engineers can ensure that their LLM applications are running at peak efficiency, enabling them to deliver improved results and drive greater value for their organizations.\n",
    "\n",
    "## Running This Notebook\n",
    "1. Step through each section below, pressing play on the code blocks to run the cells.\n",
    "2. Log in your browser to Arize App\n",
    "3. Copy and paste your Arize Space and API key\n",
    "4. For your own LLM Applications, define the arize_callback within your LLM definitions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "_X9GuXoSXleA"
   },
   "source": [
    "# Step 0. Install Dependencies, Import Libraries, Use GPU üìö\n",
    "\n",
    "Import LangChain, Arize, and Arize CallBack Handler for integration between two tools. \n",
    "\n",
    "‚ö†Ô∏è Use a GPU to save time generating embeddings. Click on 'Runtime', select 'Change Runtime Type' and\n",
    "select 'GPU'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -q langchain \n",
    "!pip3 install -q arize \n",
    "!pip3 install -q 'arize[AutoEmbeddings]'\n",
    "!pip3 install -q openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import StdOutCallbackHandler\n",
    "from langchain.callbacks.arize_callback import ArizeCallbackHandler\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VMjE6vwOOKS-"
   },
   "source": [
    "# Step 1. Import and Setup Arize Client\n",
    "\n",
    "The first step is to setup our Arize client. After that we will log the data from LangChain driven application into Arize.\n",
    "\n",
    "Retrieve your Arize `API_KEY` and `SPACE_KEY` from your Space Settings page, and paste them in the set-up section below. \n",
    "\n",
    "We will also set up some metadata and the `ArizeCallBackHandler` to use while logging.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cTB9c-TVrZd"
   },
   "source": [
    "<img src=\"https://storage.googleapis.com/arize-assets/fixtures/copy-keys.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPACE_KEY = \"YOUR_SPACE_KEY\"\n",
    "API_KEY = \"YOUR_API_KEY\"\n",
    "\n",
    "if SPACE_KEY == \"YOUR_SPACE_KEY\" or API_KEY == \"YOUR_API_KEY\":\n",
    "    raise ValueError(\"‚ùå CHANGE SPACE AND API KEYS\")\n",
    "\n",
    "# Define callback handler for Arize\n",
    "arize_callback = ArizeCallbackHandler(\n",
    "    model_id=\"llm-langchain-demo\",\n",
    "    model_version=\"1.0\",\n",
    "    SPACE_KEY=SPACE_KEY,\n",
    "    API_KEY=API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put your OPENAI API Key here!\n",
    "%env OPENAI_API_KEY=\"YOUR OPEN API KEY\"   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jjWMK3wo_FX"
   },
   "source": [
    "## Step 2: Define LLM with ArizeCallBack Handler\n",
    "Use the callback handler we defined above within the LLM with LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = CallbackManager([StdOutCallbackHandler(), arize_callback])\n",
    "llm = OpenAI(temperature=0, callback_manager=manager, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ec97f_LONfp3"
   },
   "source": [
    "## Step 3: Test LLM Responses and Logging into Arize\n",
    "Use some simple prompts to test if the LLM works properly and each prompt-response pair is logged into Arize with embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_result = llm.generate(\n",
    "    [\n",
    "        \"Tell me an interesting fact about pandas.\",\n",
    "        \"Explain the concept of overfitting in 2 sentences.\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8DGWWhYOflGZ"
   },
   "source": [
    "## Step 4: Test LLM Chain and Agents with Arize Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "\n",
    "template = \"\"\"You are a playwright. Given the title of play, it is your job to write a synopsis for that title.\n",
    "Title: {title}\n",
    "Playwright: This is a synopsis for the above play:\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"title\"], template=template)\n",
    "synopsis_chain = LLMChain(llm=llm, prompt=prompt_template, callback_manager=manager)\n",
    "\n",
    "template = \"\"\"You are a play critic from the New York Times. Given the synopsis of play, it is your job to write a review for that play.\n",
    "Play Synopsis:\n",
    "{synopsis}\n",
    "Review from a New York Times play critic of the above play:\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"synopsis\"], template=template)\n",
    "review_chain = LLMChain(llm=llm, prompt=prompt_template, callback_manager=manager)\n",
    "\n",
    "overall_chain = SimpleSequentialChain(\n",
    "    chains=[synopsis_chain, review_chain], verbose=True, callback_manager=manager\n",
    ")\n",
    "\n",
    "test_prompts = [\n",
    "    {\n",
    "        \"input\": \"documentary about pandas who are about be extinct because of global warming\"\n",
    "    },\n",
    "    {\"input\": \"once upon a time in hollywood\"},\n",
    "    {\"input\": \"the best mo observability tooling\"},\n",
    "]\n",
    "overall_chain.apply(test_prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "e4oRWiRTIGSb"
   },
   "source": [
    "### Overview\n",
    "Arize is an end-to-end ML observability and model monitoring platform. The platform is designed to help ML engineers and data science practitioners surface and fix issues with ML models in production faster with:\n",
    "- Automated ML monitoring and model monitoring\n",
    "- Workflows to troubleshoot model performance\n",
    "- Real-time visualizations for model performance monitoring, data quality monitoring, and drift monitoring\n",
    "- Model prediction cohort analysis\n",
    "- Pre-deployment model validation\n",
    "- Integrated model explainability\n",
    "\n",
    "### Website\n",
    "Visit Us At: https://arize.com/model-monitoring/\n",
    "\n",
    "### Additional Resources\n",
    "- [What is ML observability?](https://arize.com/what-is-ml-observability/)\n",
    "- [Playbook to model monitoring in production](https://arize.com/the-playbook-to-monitor-your-models-performance-in-production/)\n",
    "- [Using statistical distance metrics for ML monitoring and observability](https://arize.com/using-statistical-distance-metrics-for-machine-learning-observability/)\n",
    "- [ML infrastructure tools for data preparation](https://arize.com/ml-infrastructure-tools-for-data-preparation/)\n",
    "- [ML infrastructure tools for model building](https://arize.com/ml-infrastructure-tools-for-model-building/)\n",
    "- [ML infrastructure tools for production](https://arize.com/ml-infrastructure-tools-for-production-part-1/)\n",
    "- [ML infrastructure tools for model deployment and model serving](https://arize.com/ml-infrastructure-tools-for-production-part-2-model-deployment-and-serving/)\n",
    "- [ML infrastructure tools for ML monitoring and observability](https://arize.com/ml-infrastructure-tools-ml-observability/)\n",
    "\n",
    "Visit the [Arize Blog](https://arize.com/blog) and [Resource Center](https://arize.com/resource-hub/) for more resources on ML observability and model monitoring.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
