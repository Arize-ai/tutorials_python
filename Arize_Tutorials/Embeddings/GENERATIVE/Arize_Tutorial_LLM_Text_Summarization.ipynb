{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QOudyT6lPBqp"
   },
   "source": [
    "<img src=\"https://storage.googleapis.com/arize-assets/arize-logo-white.jpg\" width=\"200\"/>\n",
    "\n",
    "# <center>Getting Started with the Arize Platform</center>\n",
    "## <center>Investigating Text Summarization (LLM Observability)</center>\n",
    "\n",
    "**In this walkthrough, we are going to ingest data from a Large Language Model (LLM) performing text summarization.** \n",
    "\n",
    "In this scenario, you are in charge of maintaining a summarization model of a media company. Your model, MediaGPT, is tasked to summarize daily news into a concise summary. However, once the model is released into production, you notice that the performance and behavior of the model changed over a period of time and your readers around the world started to provide some negative feedback. \n",
    "\n",
    "\n",
    "This notebook will show you how Arize can automatically surface and troubleshoot the reason for this performance degradation by analyzing _prompt-response pairs_ associated with the document to be summarized so that you can take the right action to fine-tune your models. In this example, there are documents in a different language and documents also contain news about different specific topics.\n",
    "\n",
    "It is worth noting that, according to our research, inspecting embedding drift can surface problems with your data before they cause performance degradation.\n",
    "\n",
    "In this tutorial, we will start from scratch. We will:\n",
    "* Download the LLM Data we have curated for this tutorial\n",
    "* Compute generative text performance metrics with the Arize SDK\n",
    "* Automatically generate embeddings using the Arize SDK\n",
    "* Log the inferences into Arize\n",
    "* Visually explore embeddings in the Arize Platform\n",
    "\n",
    "Let's get started! "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "_X9GuXoSXleA"
   },
   "source": [
    "# Step 0. Install Dependencies, Import Libraries, Use GPU üìö\n",
    "\n",
    "To have automatic embedding generation functionality and LLM evaluation from the Arize SDK, we need\n",
    "to specify the extra `[AutoEmbeddings]` and `[NLP_Metrics]`. Note that LLM evaluation is used to\n",
    "compute evaluation metrics. If you already have metrics or embeddings computed within your dataset,\n",
    "you do not need the extra packages. \n",
    "\n",
    "‚ö†Ô∏è Use a GPU to save time generating embeddings. Click on 'Runtime', select 'Change Runtime Type' and\n",
    "select 'GPU'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q 'arize[AutoEmbeddings, NLP_Metrics]' \n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import uuid\n",
    "import pandas as pd\n",
    "\n",
    "from arize.pandas.logger import Client\n",
    "from arize.utils.types import ModelTypes, Environments, Schema, Metrics\n",
    "from arize.utils.types import Environments, ModelTypes, EmbeddingColumnNames, Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1mNretZUzlOV"
   },
   "source": [
    "# Step 1. Download the data\n",
    "\n",
    "For this tutorial, we will be using the CNN Daily News Mail dataset. This dataset is commonly used for text summarization models as a benchmark. Let's download and display the data we have available. Inside the dataset, we have: \n",
    "\n",
    "*   **document:** news article to be summarized\n",
    "*   **summary:** AI-generated summary \n",
    "*   **reference_summary:** reference summary written by domain experts\n",
    "*   **user_feedback:** thumbs down (0) or thumbs up (1) for summary feedback \n",
    "*   **prompt_template:** Template used to perform summarization task given a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download tutorial dataset\n",
    "df = pd.read_json(\"https://storage.googleapis.com/arize-assets/fixtures/Embeddings/arize-demo-models-data/GENERATIVE/summarization/generative_llm_demo_summarization.json\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9wz3nKz_b4y"
   },
   "source": [
    "# Step 2. Compute Generative Text Performance Metrics with Arize\n",
    "\n",
    "Compute SacreBLEU Score and ROUGE Score for each generated summary using the reference summary. Additional information on text-based generative AI metrics can be found [here.](https://arize.com/blog-course/generative-ai-metrics-bleu-score/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arize.pandas.generative.nlp_metrics import sacre_bleu, rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sacreBLEU_score'] = sacre_bleu( \n",
    "    response_col=df[\"summary\"], \n",
    "    references_col=df[\"reference_summary\"]\n",
    ")\n",
    "rouge_scores = rouge(\n",
    "    response_col=df[\"summary\"],\n",
    "    references_col=df[\"reference_summary\"],\n",
    "    rouge_types=[\"rougeL\"]\n",
    ")\n",
    "for rouge_type, scores in rouge_scores.items():\n",
    "    df[f\"{rouge_type}_score\"] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8IL1CYgg9U0c"
   },
   "source": [
    "# Step 3. Generate embedding vectors using Arize\n",
    "\n",
    "Arize offers the ability of generating embeddings seemlessly using large pre-trained models. In this scenario, we will use the pre-trained BERT language model. `distilbert-base-uncased`.\n",
    "\n",
    "**NOTE: We recommend utilizing GPUs to optimize embedding generation. In Google Colaboratory, navigate to the 'Runtime' menu and select 'Change runtime type'. If you are interested in accessing even more powerful GPUs, upgrade to Colab Pro for enhanced speed and performance.** \n",
    "\n",
    "The language models that Arize's embedding generators use have already been trained in such a huge amount of data that the embeddings can capture relevant structure in your data without being fine-tuned.\n",
    "\n",
    "First step is to import `EmbeddingGenerator` and `UseCases`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arize.pandas.embeddings import EmbeddingGenerator, UseCases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lYZGKBLGehLp"
   },
   "source": [
    "Next, we define our generator, choosing the model `distilbert-base-uncased`.\n",
    "\n",
    "You can also set the `batch_size`. This allows you to process the data in smaller batches if you are running out of resources. The default `batch_size` is 100.\n",
    "\n",
    "Arize then downloads the models and tokenizers from the ü§ó HuggingFace Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = EmbeddingGenerator.from_use_case(\n",
    "    use_case=UseCases.NLP.SUMMARIZATION,\n",
    "    model_name=\"distilbert-base-uncased\",\n",
    "    tokenizer_max_length=512,\n",
    "    batch_size=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ggboKMi-ehLq"
   },
   "source": [
    "To generate the embeddings, we must pass the dataframe and the name of the column in the dataframe that contains the path to the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"document_vector\"] = generator.generate_embeddings(text_col=df[\"document\"])\n",
    "df[\"summary_vector\"] = generator.generate_embeddings(text_col=df[\"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GdXnkCaDqzOj"
   },
   "source": [
    "# Step 4. Prepare your data to be sent to Arize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e37r7yiLpbvf"
   },
   "source": [
    "## Add prediction ids\n",
    "\n",
    "The Arize platform uses prediction IDs to link a prediction to an actual. Visit the [Arize documentation](https://docs.arize.com/arize/data-ingestion/model-schema/5.-prediction-id?q=prediction_id) for more details.\n",
    "\n",
    "You can generate prediction IDs as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_prediction_id(df):\n",
    "    return [str(uuid.uuid4()) for _ in range(df.shape[0])]\n",
    "df['prediction_id'] = add_prediction_id(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2JB3EFKqzOu"
   },
   "source": [
    "## Create timestamps\n",
    "In order to measure drift and performance over time, it is good to have timestamps for each prompt-response pair. We generate a synthetic timestamp for each record within the last 15 days. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now_dt = datetime.now()\n",
    "start_dt = now_dt - timedelta(days=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"prediction_ts\"] = pd.date_range(\n",
    "    start=start_dt,\n",
    "    end=now_dt,\n",
    "    periods=len(df),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VMjE6vwOOKS-"
   },
   "source": [
    "# Step 5. Sending Data into Arize üí´\n",
    "\n",
    "\n",
    "Now that we have our data configured, we are ready to log our dataset into Arize. There, the data will be easily visualized and investigated.\n",
    "\n",
    "For our model, we are going to log:\n",
    "\n",
    "*   prompt text and embeddings\n",
    "*   generated summary and embeddings\n",
    "*   reference text for the summary\n",
    "*   Rouge and SacreBleu scores we computed\n",
    "*   Prompt templates\n",
    "\n",
    "## Import and Setup Arize Client\n",
    "\n",
    "The first step is to setup our Arize client. After that we will log the data.\n",
    "\n",
    "First, use your Arize account credentials to log in. Thereafter, retrieve the Arize `API_KEY` and `SPACE_KEY` from your Space Settings page shown below! Copy those over to the set-up section. We will also be setting up some metadata to use across all logging.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cTB9c-TVrZd"
   },
   "source": [
    "<img src=\"https://storage.googleapis.com/arize-assets/fixtures/copy-keys.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPACE_KEY = \"YOUR_SPACE_KEY\"  \n",
    "API_KEY =  \"YOUR_API_KEY\"\n",
    "arize_client = Client(space_key=SPACE_KEY, api_key=API_KEY)\n",
    "if SPACE_KEY == \"YOUR_SPACE_KEY\" or API_KEY == \"YOUR_API_KEY\":\n",
    "    raise ValueError(\"‚ùå CHANGE SPACE AND API KEYS\")\n",
    "else:\n",
    "    print(\"‚úÖ Arize client setup done! Now you can start using Arize!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCMZsMpi3aiA"
   },
   "source": [
    "## Define the Schema \n",
    "\n",
    "A Schema instance specifies the column names for corresponding data in the dataframe. \n",
    "\n",
    "To ingest non-embedding features, it suffices to provide a list of column names that contain the features in our dataframe. Prompt and response pairs, however, are a little bit different since embedding vectors need to be logged into the platform.\n",
    "\n",
    "Arize allows you to ingest prompt and response pairs directly by providing `prompt_column_names` and `response_column_names` as fields of the Schema. You ingest not only the embedding vector but the raw data associated with that embedding. Therefore, up to 2 columns can be associated with the prompt or response objects:\n",
    "* Embedding `vector` (required)\n",
    "* Embedding `data` (optional,but recommended): raw text associated with the embedding vector\n",
    "\n",
    "Learn more [here](https://docs.arize.com/arize/sending-data/model-schema-reference#8.-embedding-features-unstructured).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare prompt and response columns\n",
    "prompt_columns=EmbeddingColumnNames(\n",
    "    vector_column_name=\"document_vector\",\n",
    "    data_column_name=\"document\"\n",
    ")\n",
    "\n",
    "response_columns=EmbeddingColumnNames(\n",
    "    vector_column_name=\"summary_vector\",\n",
    "    data_column_name=\"summary\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = Schema(\n",
    "    prediction_id_column_name=\"prediction_id\",\n",
    "    timestamp_column_name=\"prediction_ts\",\n",
    "    tag_column_names=[\"sacreBLEU_score\", \"rougeL_score\",\"prompt_template\", \"user_feedback\"],\n",
    "    prompt_column_names=prompt_columns,\n",
    "    response_column_names=response_columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lw8vPvEj7sUu"
   },
   "source": [
    "## Log LLM Data into Arize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = arize_client.log(\n",
    "    dataframe=df,\n",
    "    schema=schema,\n",
    "    model_id=\"demo-generative-ai-text-summarization-tutorial\",\n",
    "    model_version=\"1.0\",\n",
    "    model_type=ModelTypes.GENERATIVE_LLM,\n",
    "    environment=Environments.PRODUCTION\n",
    ")\n",
    "if response.status_code == 200:\n",
    "    print(f\"‚úÖ Successfully logged data to Arize!\")\n",
    "else:\n",
    "    print(\n",
    "        f'‚ùå Logging failed with status code {response.status_code} and message \"{response.text}\"'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MX-GEkla5Rnh"
   },
   "source": [
    "# Step 6. Confirm Data in Arize ‚úÖ\n",
    "Note that the Arize platform takes about 15 minutes to index embedding data. While the model should appear immediately, the data will not show up until the indexing is complete. Feel free to head over to the **Data Ingestion** tab for your model to watch Arize work its magic!üîÆ\n",
    "\n",
    "You will be able to see the predictions and actuals that have been sent in the last 30 minutes, last day or last week.\n",
    "\n",
    "An example view of the Data Ingestion tab from a model, when data is sent continuously over 30 minutes, is shown in the image below.\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/arize-assets/fixtures/data-ingestion-tab.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S1JYzltL8Z3g"
   },
   "source": [
    "## Check the Embedding Data in Arize\n",
    "Now, you can see how Arize surfaces the different prompt response pairs and their embeddings and troubleshoots the degradation in performance to save you the time and effort. \n",
    "\n",
    "Click on the Embeddings Tab to see how your embedding data is drifting over time. In the picture below we represent the global euclidean distance between your production set (at different points in time) and the baseline (which we set to be 2 weeks of production data, delayed by 3 days). We can see the distance is remarkably higher towards the end of the graph. This shows us that recent prompts and responses that were logged into Arize are qualitatively different in terms of content compared to 2 weeks ago Let's try to find out why the new prompt and response pairs are different using Arize!\n",
    " \n",
    "<img src=\"https://storage.googleapis.com/arize-assets/fixtures/Embeddings/GENERATIVE/High Drift Summarization.png\" width=\"900\">\n",
    "\n",
    "In addition to the drift tracking plot above, below you can find the UMAP visualization of your data, according to the point in time selected. Notice that the production data and our baseline data are superimposed, which is indicative that the model is seeing data in production similar to the data it saw 2 weeks ago. In this UMAP, notice that there are different clusters and the cluster that is kind of separated from the main big cluster of points appears only in the production dataset and has a lower rouge score. (Dataset is currently colored by rouge score, shown on the left panel). \n",
    "\n",
    "<img src=\"https://storage.googleapis.com/arize-assets/fixtures/Embeddings/GENERATIVE/UMAP 1.png\" width=\"900\">\n",
    "\n",
    "For further inspection, you may select a 3D UMAP view and clicked _Explore UMAP_ to expand the view. With this view we can interact in 3D with our dataset. We can zoom, rotate, and drag so we can see the areas of our dataset that are most interesting to us. Let's try to analyze why there is a new cluster of data that has a lower summarization score:\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/arize-assets/fixtures/Embeddings/GENERATIVE/UMAP 2.png\" width=\"900\">\n",
    "\n",
    "As you can see, this new cluster has a different language, Dutch, which does not appear in our baseline dataset, which is the data from 2 weeks ago. Now, we actually found the cause of the big jump in embedding drift on our LLM model and we can export this problematic cluster by clicking on _Download Cluster_ on the right hand side and fine-tune our model with Dutch news data. \n",
    "\n",
    "In the display above, Arize offers many coloring options:\n",
    "1. **By Dataset:** You can see that the coloring has been made to distinguish production data vs baseline data. This is specifically useful to detect drift. In this example, we can see that there is some recent production data far away from any older data, giving an indication of severe dataset drift. We can identify exactly what datapoints our baseline is missing so that we can re-train effectively.\n",
    "2. **By Performance Metric:** This coloring option gives an insight on how is our model generating summaries. By clicking on Tags and selecting one of the performance metrics, you can see which clusters are performing relatively lower compared to other clusters. \n",
    "6. **By Feature:** You can identify areas of the space where your model might be underperforming and, by coloring the points by feature, identify patterns at feature level. In other words, you can identify a slice of your data sharing a common feature (or features) that are causing a problem.\n",
    "\n",
    "More coloring options will be added to help you understand and debug your model and dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aby-AFAe6jsV"
   },
   "source": [
    "# Wrap Up üéÅ\n",
    "Congratulations, you've now sent your first Large Language Model data to the Arize platform!!\n",
    "\n",
    "Additionally, if you want to remove this example model from your account, just click **Models** -> **demo-generative-ai-text-summarization-tutorial** -> **config** -> **delete**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
