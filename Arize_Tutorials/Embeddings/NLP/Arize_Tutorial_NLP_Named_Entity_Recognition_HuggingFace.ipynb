{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QOudyT6lPBqp"
   },
   "source": [
    "<center><img src=\"https://storage.googleapis.com/arize-assets/arize-logo-white.jpg\" width=\"200\"/></center>\n",
    "\n",
    "# <center>Getting Started with the Arize Platform</center>\n",
    "## <center>Investigating Embedding Drift in NLP: Named Entity Recognition</center>\n",
    "\n",
    "**In this walkthrough, we are going to ingest embedding data and look at embedding drift.**\n",
    "\n",
    "In this scenario, you are in charge of maintaining a Named Entity Recognition (NER) model. This simple model can automatically scan text, pull out some fundamental entities within it, and classify them into predefined categories: Person, Location, or Organization. You trained your NER model on text written in English (see [dataset](https://huggingface.co/datasets/arize-ai/xtreme_en_token_drift)). However, once the model was released into production, you notice that the performance of the model has degraded over a period of time.\n",
    "\n",
    "Arize is able to surface the reason for this performance degradation. In this example, text including locations is under-represented in the training set. This label imbalance impacts the model's performance. You can surface and troubleshoot this issue by analyzing the _embedding vectors_ associated with the input text.\n",
    "\n",
    "It is worth noting that, according to our research, inspecting embedding drift can surface problems with your data before they cause performance degradation.\n",
    "\n",
    "In this tutorial, we will start from scratch. We will:\n",
    "* Download the data\n",
    "* Preprocess the data\n",
    "* Train the model\n",
    "* Extract embedding vectors and predictions\n",
    "* Log the inferences into the Arize Platform\n",
    "\n",
    "We will be using [ü§ó Hugging Face](https://huggingface.co/)'s open source libraries to make this process extremely easy. In particular, we will use:\n",
    "* [ü§ó Datasets](https://huggingface.co/docs/datasets/index): a library used for easily accessing and sharing datasets, and evaluation metrics for Natural Language Processing (NLP), computer vision, and audio tasks.\n",
    "* [ü§ó Transformers](https://huggingface.co/docs/transformers/index): a library used to easily download and use state-of-the-art pre-trained models. Using pre-trained models can lower your compute costs, reduce your carbon footprint, and save you time from training a model from scratch.\n",
    "\n",
    "**Note**: This example compares training vs production data. Arize supports sending only one dataset.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZLXgQbTr9r9s"
   },
   "source": [
    "# Step 0. Setup and Getting the Data\n",
    "\n",
    "We will first install ü§óHugging Face's `datasets` and `transformers` libraries, mentioned above. In addition, we will import some metrics from `seqeval`, an opensource library ideal for sequence labeling evaluation. Find out more [here](https://github.com/chakki-works/seqeval).\n",
    "\n",
    "We'll explain each of the imports below as we use them through this tutorial.\n",
    "\n",
    "\n",
    "## Install Dependencies and Import Libraries üìö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install datasets==2.9.0 transformers==4.26.1 seqeval arize\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    "    DataCollatorForTokenClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from seqeval.metrics import f1_score, accuracy_score\n",
    "\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "from arize.pandas.logger import Client\n",
    "from arize.utils.types import (\n",
    "    Environments,\n",
    "    ModelTypes,\n",
    "    EmbeddingColumnNames,\n",
    "    Schema,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8mF98asfZvUf"
   },
   "source": [
    "## Check if GPU is available\n",
    "Here we use Pytorch to check whether a GPU is available or not. When appropriate we will use PyTorch's `nn.Module.to()` method to ensure that the model will run on the GPU if we have one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74GhmA4Adbe2"
   },
   "source": [
    "## **üåê Download the Data**\n",
    "\n",
    "The easiest way to load a dataset is from the [Hugging Face Hub](https://huggingface.co/datasets). There are already over 6000 datasets in over 100 languages on the Hub. The [arize-ai/xtreme_en_token_drift](https://huggingface.co/datasets/arize-ai/xtreme_en_token_drift) dataset has been crafted by Arize for this example notebook.\n",
    "\n",
    "Thanks to Hugging Face ü§ó Datasets, we can download the dataset in one line of code. The `Dataset` object comes equipped with methods that make it very easy to inspect, pre-process, and post-process your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"arize-ai/xtreme_en_token_drift\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GGdI6uOXksM1"
   },
   "source": [
    "You can select the splits of the dataset as you would in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds, prod_ds = (\n",
    "    dataset[\"training\"],\n",
    "    dataset[\"validation\"],\n",
    "    dataset[\"production\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TqnORI9ck37f"
   },
   "source": [
    "## Inspect the Data\n",
    "\n",
    "It is often convenient to convert a `Dataset` object to a Pandas `DataFrame` so we can access high-level APIs for data visualization. ü§ó Datasets provides a `set_format()` method that allows us to change the output format of the `Dataset`. This does not change the underlying data format, an Arrow table. When the `DataFrame` format is no longer needed, we can reset the output format using `reset_format()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.set_format(\"pandas\")\n",
    "display(train_ds[:].head())\n",
    "train_ds.reset_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jmi6a7dfwG2S"
   },
   "source": [
    "Let's also take a look at the categories we will be classifiying into:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = train_ds.features[\"ner_tags\"].feature\n",
    "tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rPGWLvzo9r9u"
   },
   "source": [
    "These tag labels follow the [IOB2 format](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)). Let's assume you have an entity recognized as person, organization or location. The `B-` tag is applied to the first token of that _chunk_ of tokens. For the rest of tokens, the `I-` tag is used. If the word is not classified as any of the 3 options of this example, we give it the label `O`.\n",
    "\n",
    "You will see a sample sentence classified using these tag labels later in this notebook.\n",
    "\n",
    "\n",
    "**NOTE: Difference between words, tags & tokens -** Tokens are the semantical units a given piece of text is split into. Different models have different tokenization process and the tokens can vary from one model to another. Tags are the class labels that the model will assign to each token. In addition, a word can be composed of one or more tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k88BVMk9Vpp2"
   },
   "source": [
    "# Step 1. Setting up your Named Entity Recognition Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFakdDLWXwl7"
   },
   "source": [
    "## Pre-processing the data\n",
    "\n",
    "Before being able to input our data into our model for fine-tuning we need to perform some transformations: *__tokenization__* and *__label alignment__*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FmSIWFogzBHh"
   },
   "source": [
    "### Tokenization\n",
    "\n",
    "Transformer models like __*XLM-RoBERTa*__ cannot receive raw strings as input. We need to _tokenize_ and _encode_ the text as numerical vectors. We will perform _Subword Tokenization_, which is learned from the pre-training corpus. Its goal is to break complex words (or misspellings) into smaller units from which the model can learn, and to represent common words as unique entities, keeping the length of the input to a reasonable size.\n",
    "\n",
    "ü§ó Transformers provides the `AutoTokenizer` class, which allows us to quickly download the tokenizer required by the pre-trained model of our choosing.\n",
    "\n",
    "In this case, we will use the following __checkpoint__: `xlm-roberta-base`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = \"xlm-roberta-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACTMQG-mXouh"
   },
   "source": [
    "Next, let's define a function to tokenize the examples in the dataset. The `padding` and `truncation` options are added to keep the inputs to a consistent length. Shorter sequences are _padded_ and longer ones are _truncated_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch, max_length=512):\n",
    "    return tokenizer(\n",
    "        batch[\"split_text\"],\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        is_split_into_words=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AAvwQdJQx3W3"
   },
   "source": [
    "### Label alignment\n",
    "\n",
    "The tokenizer returns `input_ids` and `attention_mask` for the model's inputs, both padded and truncated if the options above are set to `True`. However, the `ner_tags` column is not of the same length. This is because the `ner_tags` are assigned to each word. But after tokenization, words are split into tokens. Hence, there is a misalignment between the tags and the tokens.\n",
    "\n",
    "To fix this, we need to assign a tag to each token. The following function does the trick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels(batch, tokenized_inputs):\n",
    "    labels = []\n",
    "    for idx, tags in enumerate(batch[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=idx)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None or word_idx == previous_word_idx:\n",
    "                label_ids.append(-100)\n",
    "            else:\n",
    "                label_ids.append(tags[word_idx])\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CqnYNgjY9r9u"
   },
   "source": [
    "It uses the `word_ids` to distinguish which tokens belong to which word. If the word ID is `None` it means that the token does not belong to a word, i.e., the `[SEP]` or `[CLS]` tokens. Moreover, some words are split into different tokens. Since the lowest granularity of an entity is the word, all tokens in the word must be classified with the same tag. To achieve this, the model will focus its attention on the first token of the word and ignore the rest.\n",
    "\n",
    "In short, we want the model to ignore tokens not belonging to words and sub-word tokens excluding the first by assigning the label -100. This will tell `PyTorch` to ignore these labels when it computes the loss.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3YCI70a0x-fn"
   },
   "source": [
    "### Apply to dataset\n",
    "\n",
    "Now we apply the transformations above to the entire dataset using the `map()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(batch):\n",
    "    max_length = 128  # max length of the tokenized sequence\n",
    "    tokenized_inputs = tokenize(batch, max_length)\n",
    "    tokenized_inputs[\"labels\"] = align_labels(batch, tokenized_inputs)\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_batch_size = 100\n",
    "\n",
    "train_ds = train_ds.map(\n",
    "    preprocess,\n",
    "    batched=True,\n",
    "    batch_size=process_batch_size,\n",
    "    remove_columns=[\"ner_tags\"],\n",
    ")\n",
    "val_ds = val_ds.map(\n",
    "    preprocess,\n",
    "    batched=True,\n",
    "    batch_size=process_batch_size,\n",
    "    remove_columns=[\"ner_tags\"],\n",
    ")\n",
    "prod_ds = prod_ds.map(\n",
    "    preprocess,\n",
    "    batched=True,\n",
    "    batch_size=process_batch_size,\n",
    "    remove_columns=[\"ner_tags\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xaTcmuGHYkw2"
   },
   "source": [
    "In the following view of our dataset, two columns have appeared:\n",
    "* `input_ids`: A numerical identifier to which each token has been mapped.\n",
    "* `attention_mask`: Array of 1s and 0s, allowing the model to ignore the padded parts of the inputs.\n",
    "\n",
    "Notice that we have replaced the `ner_tags` column with `labels`. The information is the same, but now the `labels` are aligned with `input_ids`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.set_format(type=\"pandas\")\n",
    "display(train_ds[:].head())\n",
    "train_ds.reset_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3iWr5iV9r9v"
   },
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2BRkjnUQZtlB"
   },
   "source": [
    "Similar to how we obtained the tokenizer, ü§ó Transformers provides the `AutoModelForTokenClassification` class, which allows us to quickly download a pre-trained transformer model with a token classification [task head](https://huggingface.co/course/en/chapter2/2?fw=pt#model-heads-making-sense-out-of-numbers) on top. The pre-trained model to use in this tutorial is [XLM-RoBERTa](https://huggingface.co/xlm-roberta-base). The weights of the token classification task head will be randomly initialized.\n",
    "\n",
    "It is important to pass `output_hidden_states = True` to be able to compute the embedding vectors associated with the text (explained below).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Itstofej9r9v"
   },
   "source": [
    "In addition, we will need to provide the mapping of each tag label to a tag ID and vice versa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2tag = {idx: tag for idx, tag in enumerate(tags.names)}\n",
    "tag2index = {tag: idx for idx, tag in enumerate(tags.names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"XLM-RoBERTa-xtreme-en-token-drift\"\n",
    "SKIP_TRAINING = False  # Make True if you want to skip training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_21iUmxO9r9v"
   },
   "source": [
    "### A) Fine-tune the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JVsqCnYUn6Hu"
   },
   "source": [
    "You will require Google Colab Pro or Pro+ to fine-tune the model in section A). If you want to avoid the cost, you can skip section A), set `SKIP_TRAINING = True` and go to [_B) Download the model_](#B\\)-Download-the-fine-tuned-model).\n",
    "\n",
    "Let's download the pre-trained model,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_ckpt,\n",
    "    num_labels=tags.num_classes,\n",
    "    id2label=index2tag,\n",
    "    label2id=tag2index,\n",
    "    output_hidden_states=True,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MzPrZT3ObVYM"
   },
   "source": [
    "Further, we use the `TrainingArguments` class to define the training parameters. This class stores a lot of information and gives you control over the training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_batch_size = 32\n",
    "training_epochs = 3\n",
    "logging_steps = len(train_ds) // training_batch_size\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_name,\n",
    "    num_train_epochs=training_epochs,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=training_batch_size,\n",
    "    per_device_eval_batch_size=training_batch_size,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    disable_tqdm=False,\n",
    "    logging_steps=logging_steps,\n",
    "    log_level=\"error\",\n",
    "    optim=\"adamw_torch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_PldqLRn3qnS"
   },
   "source": [
    "When evaluating an NER model, _all_ words of an entity need to be predicted correctly in order for a prediction to be counted as correct. For instance, if our model prediction was `New[LOC] York[PER]` it would not be correct. We would need both words predicted correctly, `New[LOC] York[LOC]`, for the entity prediction to be correct. For this purpose, we use the library `seqeval` ([github.com/chakki-works/seqeval](https://github.com/chakki-works/seqeval)).\n",
    "\n",
    "The following functions will:\n",
    "1. Remove the prediction and actual labels marked with -100, which should be ignored when computing metrics.\n",
    "2. Compute the evaluation metrics on the two sequences of tag labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_labels_of_ignored_tokens(predictions, label_ids):\n",
    "    batch_preds = np.argmax(predictions, axis=2)\n",
    "    batch_size, seq_len = batch_preds.shape\n",
    "    actuals_list, preds_list = [], []\n",
    "\n",
    "    for batch_idx in range(batch_size):\n",
    "        actuals, preds = [], []\n",
    "        for seq_idx in range(seq_len):\n",
    "            # Ignore label IDs = -100\n",
    "            if label_ids[batch_idx, seq_idx] != -100:\n",
    "                actuals.append(index2tag[label_ids[batch_idx][seq_idx]])\n",
    "                preds.append(index2tag[batch_preds[batch_idx][seq_idx]])\n",
    "\n",
    "        actuals_list.append(actuals)\n",
    "        preds_list.append(preds)\n",
    "\n",
    "    return preds_list, actuals_list\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    y_pred, y_true = remove_labels_of_ignored_tokens(\n",
    "        pred.predictions[0], pred.label_ids\n",
    "    )\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"f1\": f1_score(y_true, y_pred, average=\"weighted\"),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NsrojG6tAA9N"
   },
   "source": [
    "Next, we need a _data collator_ so that we can pad each input sequence to match the length of the largest sequence in a batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k3_wd_bQcATp"
   },
   "source": [
    "\n",
    "Finally, we can fine-tune our model using the `Trainer` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SKIP_TRAINING == False:\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=val_ds,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "\n",
    "    print(\"Evaluation before training\")\n",
    "    eval = trainer.evaluate(eval_dataset=val_ds)\n",
    "    eval_df = pd.DataFrame(\n",
    "        {\n",
    "            \"Epoch\": 0,\n",
    "            \"Validation Loss\": eval[\"eval_loss\"],\n",
    "            \"Accuracy\": eval[\"eval_accuracy\"],\n",
    "            \"F1\": eval[\"eval_f1\"],\n",
    "        },\n",
    "        index=[0],\n",
    "    )\n",
    "    display(eval_df)\n",
    "    print(\" \")\n",
    "\n",
    "    torch.cuda.empty_cache()  # Free up some memory\n",
    "\n",
    "    print(\"\\nTraining...\")\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQNDrjIEv4qb"
   },
   "source": [
    "### B) Download the fine-tuned model\n",
    "\n",
    "If you decided to skip step 1, you can download the already fine-tuned model [arize-ai/XLM-RoBERTa-xtreme-en-token-drift](https://huggingface.co/arize-ai/XLM-RoBERTa-xtreme-en-token-drift) from Arize's page in the Hugging Face Hub.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (\n",
    "    SKIP_TRAINING == True\n",
    "):  # Make sure you marked SKIP_TRAINING = True if you wanted to skip training\n",
    "    model_ckpt = f\"arize-ai/{model_name}\"\n",
    "\n",
    "    model = AutoModelForTokenClassification.from_pretrained(\n",
    "        model_ckpt, num_labels=tags.num_classes, output_hidden_states=True\n",
    "    ).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PYoJbgzR9r9w"
   },
   "source": [
    "## Try out the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jrPAz1StA6wy"
   },
   "source": [
    "If you want to get a feel of how the fine-tuned model performs with specific text you want to pass as input, the following is a helper function so we can try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tags(split_text, index2tag, tokenizer, model):\n",
    "    # Get tokens with special characters\n",
    "    tokens = tokenizer(list(split_text), is_split_into_words=True).tokens()\n",
    "    # Encode the sequence into IDs\n",
    "    input_ids = tokenizer(\n",
    "        list(split_text), is_split_into_words=True, return_tensors=\"pt\"\n",
    "    ).input_ids.to(device)\n",
    "    # Get predictions as distribution over 7 possible classes\n",
    "    logits = model(input_ids).logits\n",
    "    # Take argmax to get most likely class per token\n",
    "    predictions = torch.argmax(logits, dim=2).squeeze().cpu().numpy()\n",
    "    # Convert to DataFrame\n",
    "    preds = [index2tag[p] for p in predictions]\n",
    "\n",
    "    return pd.DataFrame([tokens, preds], index=[\"Tokens\", \"Predicted Tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"My name is Julia, I study at Imperial College, in London\".split(\" \")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "show_tags(text, index2tag, tokenizer, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M4s3W8gthBcb"
   },
   "source": [
    "As we can see in the table above, our model fails to understand locations. This is not surprising given that the dataset we used to train it was crafted in such a way that the `LOC` tokens are very under represented in the training set.\n",
    "\n",
    "We will see how Arize is able to surface this problem once the data is ingested into the platform.\n",
    "\n",
    "If you'd like to ingest data from a model without this problem you can do one of the following:\n",
    "* Substitute the current model with a model fine-tuned on a dataset without this representation problem, and keep going from here (note that it is missing `-token-drift`).\n",
    "```\n",
    "model_ckpt = f\"arize-ai/XLM-RoBERTa-xtreme-en\"\n",
    "model = (AutoModelForTokenClassification\n",
    "        .from_pretrained(model_ckpt,\n",
    "                         num_labels = tags.num_classes,\n",
    "                         output_hidden_states=True\n",
    "                        )\n",
    "        .to(device))\n",
    "```\n",
    "\n",
    "* If you want to obtain a fine-tuned model like the one above, substitute the dataset downloaded at the beginning of this tutorial for one without this problem (note that it is missing `_token_drift`). Then, run the notebook again executing the [fine-tuning step](#A\\)-Fine-tune-the-model).\n",
    "```\n",
    "dataset = load_dataset(\"arize-ai/xtreme_en\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7YBqdsebIF_"
   },
   "source": [
    "# Step 2. Post-Processing your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "klUW0X57mVdA"
   },
   "source": [
    "## Get model outputs\n",
    "Now we will extract the prediction labels and the text embedding vectors. The latter are formed from the hidden states of our pre-trained (and then fine-tuned) model. We will choose the last hidden layer to compute our embeddings. We get the whole layer now so in a later function we can compute the desired token embedding vector from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_outputs(batch):\n",
    "    # Get model inputs, convert dict of lists to list of dicts suitable for data collator\n",
    "    inputs = {\n",
    "        k: v.to(device)\n",
    "        for k, v in batch.items()\n",
    "        if k in tokenizer.model_input_names\n",
    "    }\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Pass data through model\n",
    "        output = model(**inputs)\n",
    "        predicted_labels = torch.argmax(output.logits, dim=2).cpu().numpy()\n",
    "        hidden_states = (\n",
    "            torch.stack(output.hidden_states).cpu().numpy()\n",
    "        )  # (layer_#, batch_size, seq_length/or/num_tokens, hidden_size)\n",
    "\n",
    "    return {\n",
    "        \"pred_labels\": predicted_labels,\n",
    "        \"last_hidden_state\": hidden_states[-1],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "train_ds = train_ds.map(\n",
    "    get_model_outputs, batched=True, batch_size=process_batch_size\n",
    ")\n",
    "\n",
    "val_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "val_ds = val_ds.map(\n",
    "    get_model_outputs, batched=True, batch_size=process_batch_size\n",
    ")\n",
    "\n",
    "prod_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "prod_ds = prod_ds.map(\n",
    "    get_model_outputs, batched=True, batch_size=process_batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1_MU-v3mhSJ"
   },
   "source": [
    "## Expand the dataset\n",
    "\n",
    "We want to send in words and their labels as single predictions.\t\n",
    "\n",
    "Each record sent to the Arize platform can contain one prediction label and one actual label. In the case of NER, for each individual input sequence to the model there is a sequence of prediction/actual tags. However, we want to send individual words and their tag labels as single a prediction/acutal.\n",
    "\n",
    "For this purpose, we will _explode_ the dataframe on the columns: `labels`, `pred_labels`, `word_ids`, and `token_embeddings`. You can visualize the result of this process a few cells below.\n",
    "\n",
    "Since this can dramatically increase the size of our example, we will filter out the cases when both the prediction and actual agree that the label is \"O\" (representing miscellaneous entities, not Person, Organization or Location)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2tag[-100] = \"IGN\"\n",
    "\n",
    "\n",
    "def find_label_indexes(labels, pred_labels):\n",
    "    token_index_list = []\n",
    "    for i in range(1, len(labels) - 1):\n",
    "        label = labels[i]\n",
    "        pred_label = pred_labels[i]\n",
    "        if (label == \"IGN\") or (label == \"O\" and pred_label == \"O\"):\n",
    "            continue\n",
    "        token_index_list.append(i)\n",
    "    return token_index_list\n",
    "\n",
    "\n",
    "def filter_labels(labels, filters):\n",
    "    return [labels[index] for index in filters]\n",
    "\n",
    "\n",
    "def filter_word_ids(word_ids, filters):\n",
    "    return [word_ids[index] for index in filters]\n",
    "\n",
    "\n",
    "def get_token_embeddings(last_hidden_state, filters):\n",
    "    return [np.stack(last_hidden_state)[index, :] for index in filters]\n",
    "\n",
    "\n",
    "def mark_word_in_text(split_text, word_id):\n",
    "    marked_text = split_text[:word_id].tolist()\n",
    "    marked_text.append(\">\" + split_text[word_id] + \"<\")\n",
    "    marked_text += split_text[word_id + 1 :].tolist()\n",
    "    return \" \".join(marked_text)\n",
    "\n",
    "\n",
    "def postprocess(df):\n",
    "    # Helper column (will be deleted) so we can truncate the different arrays on each row\n",
    "    df[\"N\"] = df[\"attention_mask\"].map(lambda x: x.sum())\n",
    "    # Truncate the input_ids, labels, and pred_labels columns using the attention_mask\n",
    "    df[\"input_ids\"] = df.apply(lambda row: row[\"input_ids\"][: row[\"N\"]], axis=1)\n",
    "    df[\"labels\"] = df.apply(lambda row: row[\"labels\"][: row[\"N\"]], axis=1)\n",
    "    df[\"pred_labels\"] = df.apply(\n",
    "        lambda row: row[\"pred_labels\"][: row[\"N\"]], axis=1\n",
    "    )\n",
    "\n",
    "    # Translate the label IDs to their tag name\n",
    "    df[\"labels\"] = df[\"labels\"].apply(\n",
    "        lambda x: [index2tag[index] for index in x]\n",
    "    )\n",
    "    df[\"pred_labels\"] = df[\"pred_labels\"].apply(\n",
    "        lambda x: [index2tag[index] for index in x]\n",
    "    )\n",
    "\n",
    "    # Get word_ids, this will be used to mark what word each prediction/actual will be corresponding to\n",
    "    df[\"word_ids\"] = df[\"split_text\"].map(\n",
    "        lambda split_text: tokenizer(\n",
    "            list(split_text), is_split_into_words=True\n",
    "        ).word_ids()\n",
    "    )\n",
    "\n",
    "    # We create a filter so we don't send to Arize the \"IGN\" labels and the redundant \"O\" labels (when both prediction and actuals agree to be \"O\"),\n",
    "    # \"O\" labels are assigned to words that are not \"LOC\", \"PER\", or \"ORG\".\n",
    "    # index_filter will be the indexes of those tokens to be considered and sent into Arize\n",
    "    df[\"index_filter\"] = df.apply(\n",
    "        lambda row: find_label_indexes(row[\"labels\"], row[\"pred_labels\"]),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Use `index_filter` to filter labels and word_ids\n",
    "    df[\"labels\"] = df.apply(\n",
    "        lambda row: filter_labels(row[\"labels\"], row[\"index_filter\"]), axis=1\n",
    "    )\n",
    "    df[\"pred_labels\"] = df.apply(\n",
    "        lambda row: filter_labels(row[\"pred_labels\"], row[\"index_filter\"]),\n",
    "        axis=1,\n",
    "    )\n",
    "    df[\"word_ids\"] = df.apply(\n",
    "        lambda row: filter_word_ids(row[\"word_ids\"], row[\"index_filter\"]),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # We will get the token embeddings from the last_hidden_state layer, specifically using the token index from index_filter\n",
    "    df[\"token_embeddings\"] = df.apply(\n",
    "        lambda row: get_token_embeddings(\n",
    "            row[\"last_hidden_state\"], row[\"index_filter\"]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # We can now drop some columns that are no longer needed\n",
    "    df.drop(\n",
    "        columns=[\n",
    "            \"input_ids\",\n",
    "            \"attention_mask\",\n",
    "            \"last_hidden_state\",\n",
    "            \"N\",\n",
    "            \"index_filter\",\n",
    "        ],\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    # We will expand our dataset to get predictions, actuals, and embeddings corresponding to individual tokens\n",
    "    df = df.explode([\"labels\", \"pred_labels\", \"word_ids\", \"token_embeddings\"])\n",
    "\n",
    "    # Finally, we create a \"text\" column to be the raw text from which the prediction takes place, marking the word of interest\n",
    "    # for this inference event\n",
    "    df[\"split_text\"] = df.apply(\n",
    "        lambda row: mark_word_in_text(row[\"split_text\"], row[\"word_ids\"]),\n",
    "        axis=1,\n",
    "    )\n",
    "    df.rename(columns={\"split_text\": \"text\"}, inplace=True)\n",
    "\n",
    "    return df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LSukMx0h5L8Q"
   },
   "source": [
    "From this point forward, it is convenient to use Pandas DataFrames. We can do so easily using the format methods we have seen already.\n",
    "\n",
    "You may require Google Colab Pro or Pro+ to run this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.set_format(\"pandas\")\n",
    "train_df = postprocess(train_ds[:])\n",
    "\n",
    "val_ds.set_format(\"pandas\")\n",
    "val_df = postprocess(val_ds[:])\n",
    "\n",
    "prod_ds.set_format(\"pandas\")\n",
    "prod_df = postprocess(prod_ds[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YqQizJwmpYty"
   },
   "source": [
    "Visualize our dataset after the many transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0BIeGAemfziv"
   },
   "source": [
    "# Step 3. Prepare your data to be sent to Arize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cyer0ywollCt"
   },
   "source": [
    "## Update the timestamps\n",
    "\n",
    "The data that you are working with was constructed in April of 2022. Hence, we will update the timestamps so they are current at the time that you're sending data to Arize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_ts = max(prod_df[\"prediction_ts\"])\n",
    "now_ts = datetime.timestamp(datetime.now())\n",
    "delta_ts = now_ts - last_ts\n",
    "\n",
    "train_df[\"prediction_ts\"] = (train_df[\"prediction_ts\"] + delta_ts).astype(float)\n",
    "val_df[\"prediction_ts\"] = (val_df[\"prediction_ts\"] + delta_ts).astype(float)\n",
    "prod_df[\"prediction_ts\"] = (prod_df[\"prediction_ts\"] + delta_ts).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e37r7yiLpbvf"
   },
   "source": [
    "## Add prediction ids\n",
    "\n",
    "The Arize platform uses prediction IDs to link a prediction to an actual. Visit the [Arize documentation](https://docs.arize.com/arize/data-ingestion/model-schema/5.-prediction-id?q=prediction_id) for more details.\n",
    "\n",
    "You can generate prediction IDs as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_prediction_id(df):\n",
    "    return [str(uuid.uuid4()) for _ in range(df.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"prediction_id\"] = add_prediction_id(train_df)\n",
    "val_df[\"prediction_id\"] = add_prediction_id(val_df)\n",
    "prod_df[\"prediction_id\"] = add_prediction_id(prod_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3yld8w_L-YOG"
   },
   "source": [
    "# Step 4. Sending Data into Arize üí´\n",
    "\n",
    "## Select the columns we want to send to Arize (optional)\n",
    "\n",
    "This step is not really necessary, since we will select the columns we want to send to Arize using the `Schema` definition (below). However, for the purpose of visibility, this is our final `DataFrame` with the data that will be sent to Arize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arize_columns = [\n",
    "    \"prediction_id\",\n",
    "    \"prediction_ts\",\n",
    "    \"language\",\n",
    "    \"text\",\n",
    "    \"labels\",\n",
    "    \"pred_labels\",\n",
    "    \"token_embeddings\",\n",
    "]\n",
    "\n",
    "train_df = train_df[arize_columns]\n",
    "val_df = val_df[arize_columns]\n",
    "prod_df = prod_df[arize_columns]\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pwvCUBqkeW4V"
   },
   "source": [
    "## Import and Setup Arize Client\n",
    "\n",
    "The first step is to setup the Arize client. After that we will log the data.\n",
    "\n",
    "Copy the Arize `API_KEY` and `SPACE_ID` from your Space Settings page (shown below) to the variables in the cell below. We will also be setting up some metadata to use across all logging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j3jd6J3qQb_K"
   },
   "source": [
    "<img src=\"https://storage.googleapis.com/arize-assets/fixtures/copy-id-and-key.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPACE_ID = \"SPACE_ID\"\n",
    "API_KEY = \"API_KEY\"\n",
    "arize_client = Client(space_id=SPACE_ID, api_key=API_KEY)\n",
    "model_id = \"NLP-demo-hf-NER-token-drift\"  # Remove '-token-drift' if you chose a model without the drifting problem\n",
    "model_version = \"1.0\"\n",
    "model_type = ModelTypes.SCORE_CATEGORICAL\n",
    "if SPACE_ID == \"SPACE_ID\" or API_KEY == \"API_KEY\":\n",
    "    raise ValueError(\"‚ùå CHANGE SPACE_ID AND/OR API_KEY\")\n",
    "else:\n",
    "    print(\n",
    "        \"‚úÖ Import and Setup Arize Client Done! Now we can start using Arize!\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhYZ7xOVfasj"
   },
   "source": [
    "\n",
    "Now that our Arize client is setup, let's go ahead and log all of our data to the platform. For more details on how **`arize.pandas.logger`** works, visit our documentation.\n",
    "\n",
    "[![Buttons_OpenOrange.png](https://storage.googleapis.com/arize-assets/fixtures/Buttons_OpenOrange.png)](https://docs.arize.com/arize/sdks-and-integrations/python-sdk/arize.pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCMZsMpi3aiA"
   },
   "source": [
    "## Define the Schema\n",
    "\n",
    "A Schema instance specifies the column names for corresponding data in the dataframe. While we could define different Schemas for training and production datasets, the dataframes have the same column names, so the Schema will be the same in this instance.\n",
    "\n",
    "To ingest non-embedding features, it suffices to provide a list of column names that contain the features in our dataframe. Embedding features, however, are a little bit different.\n",
    "\n",
    "Arize allows you to ingest not only the embedding vector, but the raw data associtated with that embedding, or a URL link to that raw data. Therefore, up to 3 columns can be associated to the same _embedding object_*. To be able to do this, Arize's SDK provides the `EmbeddingColumnNames` class, used below.\n",
    "\n",
    "*NOTE: This is how we refer to the 3 possible pieces of information that can be sent as embedding objects:\n",
    "* Embedding `vector` (required)\n",
    "* Embedding `data` (optional): raw text associated with the embedding vector\n",
    "* Embedding `link_to_data` (optional): link to the data file (image, audio, ...) associated with the embedding vector\n",
    "tor\n",
    "\n",
    "Learn more [here](https://docs.arize.com/arize/sending-data/model-schema-reference#8.-embedding-features-unstructured)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"language\",\n",
    "]\n",
    "\n",
    "embedding_features = {\n",
    "    # Dictionary keys will be the displayed name of the embedding feature in the app\n",
    "    \"token_embedding\": EmbeddingColumnNames(\n",
    "        vector_column_name=\"token_embeddings\",\n",
    "        data_column_name=\"text\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Define a Schema() object for Arize to pick up data from the correct columns for logging\n",
    "schema = Schema(\n",
    "    prediction_id_column_name=\"prediction_id\",\n",
    "    timestamp_column_name=\"prediction_ts\",\n",
    "    prediction_label_column_name=\"pred_labels\",\n",
    "    actual_label_column_name=\"labels\",\n",
    "    feature_column_names=features,\n",
    "    embedding_feature_column_names=embedding_features,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lw8vPvEj7sUu"
   },
   "source": [
    "## Log Training Data\n",
    "\n",
    "**Note**: This example compares training vs production data. Arize supports sending only one dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging Training DataFrame\n",
    "response = arize_client.log(\n",
    "    dataframe=train_df,\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    model_type=model_type,\n",
    "    environment=Environments.TRAINING,\n",
    "    schema=schema,\n",
    ")\n",
    "\n",
    "\n",
    "# If successful, the server will return a status_code of 200\n",
    "if response.status_code != 200:\n",
    "    print(\n",
    "        f\"‚ùå logging failed with response code {response.status_code}, {response.text}\"\n",
    "    )\n",
    "else:\n",
    "    print(\"‚úÖ You have successfully logged training set to Arize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6dEt_DLx2bYl"
   },
   "source": [
    "## Log Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging Validation DataFrame\n",
    "response = arize_client.log(\n",
    "    dataframe=val_df,\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    batch_id=\"validation\",\n",
    "    model_type=model_type,\n",
    "    environment=Environments.VALIDATION,\n",
    "    schema=schema,\n",
    ")\n",
    "\n",
    "\n",
    "# If successful, the server will return a status_code of 200\n",
    "if response.status_code != 200:\n",
    "    print(\n",
    "        f\"‚ùå logging failed with response code {response.status_code}, {response.text}\"\n",
    "    )\n",
    "else:\n",
    "    print(\"‚úÖ You have successfully logged training set to Arize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dLeCjcQRDWF6"
   },
   "source": [
    "## Log Production Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging Production DataFrame\n",
    "response = arize_client.log(\n",
    "    dataframe=prod_df,\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    model_type=model_type,\n",
    "    environment=Environments.PRODUCTION,\n",
    "    schema=schema,\n",
    ")\n",
    "\n",
    "if response.status_code != 200:\n",
    "    print(\n",
    "        f\"‚ùå logging failed with response code {response.status_code}, {response.text}\"\n",
    "    )\n",
    "else:\n",
    "    print(\"‚úÖ You have successfully logged production set to Arize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MX-GEkla5Rnh"
   },
   "source": [
    "# Step 5. Confirm Data in Arize ‚úÖ\n",
    "Note that the Arize platform takes about 15 minutes to index embedding data. While the model should appear immediately, the data will not show up until the indexing is complete. Feel free to head over to the **Data Ingestion** tab for your model to watch Arize work its magic!üîÆ\n",
    "\n",
    "You will be able to see the predictions, actuals, and feature importances that have been sent in the last 30 minutes, last day or last week.\n",
    "\n",
    "An example view of the Data Ingestion tab from a model, when data is sent continuously over 30 minutes, is shown in the image below.\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/arize-assets/fixtures/data-ingestion-tab.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S1JYzltL8Z3g"
   },
   "source": [
    "# Step 6. Check the Embedding Data in Arize\n",
    "\n",
    "First, set the baseline to the training set that we logged in the previous section.\n",
    "\n",
    "<img src=\"https://storage.cloud.google.com/arize-assets/fixtures/embedding_setup_baseline.gif\" width=\"700\">\n",
    "\n",
    "Once data is ingested and models contain embedding data, you will see it on the Model Overview page.\n",
    "\n",
    "<img src=\"https://storage.cloud.google.com/arize-assets/fixtures/Embeddings/NLP/NER-token-drift-overview.jpg\" width=\"700\">\n",
    "\n",
    "Click on the Embedding Name or the Euclidean Distance value to see how your embedding data is drifting over time. In the picture below, we represent the global euclidean distance between your production set (at different points in time) and the baseline (which we set to be our training set).\n",
    "\n",
    "We can see there is a period of a week where suddenly the distance is remarkably higher. When the drift distance is high, the tag proportions in our production set are different to those of the baseline. Conversely, when the drift distance is low, the tag proportions in our production set are similar to those of the baseline. More precisely, the LOC tags in the baseline were under-represented. Hence, when they are reasonably present in production, we observe higher drift values.\n",
    "\n",
    "<img src=\"https://storage.cloud.google.com/arize-assets/fixtures/Embeddings/NLP/NER-token-drift-emb-0.jpg\" width=\"700\">\n",
    "\n",
    "In addition to the drift tracking plot above, below you can find the UMAP visualization of your data, according to the point in time selected. Notice that the production data and our baseline (training) data are superimposed, which is indicative that the model is seeing data in production similar to the data it was trained on.\n",
    "\n",
    "<img src=\"https://storage.cloud.google.com/arize-assets/fixtures/Embeddings/NLP/NER-token-drift-emb-1.jpg\" width=\"700\">\n",
    "\n",
    "Next, select a point in time when the drift was high and generate a UMAP visualization in 2D. We can see that both training and production data are superimposed for the most part, with the exception of two areas of production data that have no training data present. This indicates that the model is seeing data in production qualitatively different from the data it was trained on, and in this case causing performance degradation.\n",
    "\n",
    "<img src=\"https://storage.cloud.google.com/arize-assets/fixtures/Embeddings/NLP/NER-token-drift-emb-2.jpg\" width=\"700\">\n",
    "\n",
    "You can also choose to color your data points by prediction label. This is very useful to gather insight on how your model is thinking about the inputs, and identify any potential flaws in your model's decision process. For instance, in the following image there are some purple data points close to the brown cluster. You can inspect those points and determine if the model is wrong or there is a labeling problem. You can also identify patterns in the common mistakes the model makes that will help root cause the problem.\n",
    "\n",
    "<img src=\"https://storage.cloud.google.com/arize-assets/fixtures/Embeddings/NLP/NER-token-drift-emb-3.jpg\" width=\"700\">\n",
    "\n",
    "For further inspection, generate the UMAP vizualization in 3D, and click _\"Explore UMAP\"_. With this view, you can interact with the dataset in 3D. You can zoom, rotate, and drag to see any areas of interest within the dataset.\n",
    "\n",
    "<img src=\"https://storage.cloud.google.com/arize-assets/fixtures/Embeddings/NLP/NER-token-drift-workflow.gif\" width=\"700\">\n",
    "\n",
    "In the display above, Arize offers many coloring options:\n",
    "1. By Dataset: You can see that the coloring has been made to distinguish production data vs baseline data (training in this example). This is specifically useful to detect drift by locating the areas where there are production data-points present but not (or not as many) baseline data-points. This gives an indication of severe dataset drift. We can identify exactly what datapoints our baseline is missing so that re-train effectively.\n",
    "2. By Prediction Label: This coloring option gives an insight on how is our model making decisions. Where are the different classes located in the space? Is the model predicting one class in regions where it should be predicting another?\n",
    "3. By Actual Label: This coloring option is great if we want to identify labeling issues. For instance, if inside the orange cloud, we can see a points of other colors, it is a good idea to check and see if the labels are wrong. Further we can use the corrected labels for re-training. This separation is specially difficult when clusters are joined, since both the model and UMAP have trouble separating the data-points.\n",
    "4. By Correctness: This coloring option offers a quick way of identifying where the bulk of your model's mistakes are placed, giving you an area to pay attention to. In this example, we can see that the spanish reviews are almost all red.\n",
    "5. By Confusion Matrix: This coloring option allows you to select a `positive class` and color the data-points as `True Positives`, `True Negatives`, `False Positives`, `False Negatives`.\n",
    "6. By Feature: You can identify areas of the space where your model might be underperforming and, by coloring the points by feature, identify patterns at feature level. In other words, you can identify a slice of your data sharing a common feature (or features) that are causing a problem.\n",
    "7. By Prediction Score: You can identify areas where your model is more confident of its predictions and areas where your model struggled more to make a decision.\n",
    "\n",
    "More coloring options will be added to help you understand and debug your model and dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aby-AFAe6jsV"
   },
   "source": [
    "# Wrap Up üéÅ\n",
    "Congratulations, you've now sent your first machine learning embedding data to the Arize platform!!\n",
    "\n",
    "Additionally, if you want to remove this example model from your account, just click **Models** -> **NLP-demo-NER-token-drift** -> **config** -> **delete**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TP304Ecf6ePX"
   },
   "source": [
    "### Overview\n",
    "Arize is an end-to-end ML observability and model monitoring platform. The platform is designed to help ML engineers and data science practitioners surface and fix issues with ML models in production faster with:\n",
    "- Automated ML monitoring and model monitoring\n",
    "- Workflows to troubleshoot model performance\n",
    "- Real-time visualizations for model performance monitoring, data quality monitoring, and drift monitoring\n",
    "- Model prediction cohort analysis\n",
    "- Pre-deployment model validation\n",
    "- Integrated model explainability\n",
    "\n",
    "### Website\n",
    "Visit Us At: https://arize.com/model-monitoring/\n",
    "\n",
    "### Additional Resources\n",
    "- [What is ML observability?](https://arize.com/what-is-ml-observability/)\n",
    "- [Monitor Unstructured Data with Arize](https://arize.com/blog/monitor-unstructured-data-with-arize)\n",
    "- [Getting Started With Embeddings Is Easier Than You Think](https://arize.com/blog/getting-started-with-embeddings-is-easier-than-you-think)\n",
    "- [Playbook to model monitoring in production](https://arize.com/the-playbook-to-monitor-your-models-performance-in-production/)\n",
    "- [Using statistical distance metrics for ML monitoring and observability](https://arize.com/using-statistical-distance-metrics-for-machine-learning-observability/)\n",
    "<!-- - [ML infrastructure tools for data preparation](https://arize.com/ml-infrastructure-tools-for-data-preparation/) -->\n",
    "- [ML infrastructure tools for model building](https://arize.com/ml-infrastructure-tools-for-model-building/)\n",
    "- [ML infrastructure tools for production](https://arize.com/ml-infrastructure-tools-for-production-part-1/)\n",
    "<!-- - [ML infrastructure tools for model deployment and model serving](https://arize.com/ml-infrastructure-tools-for-production-part-2-model-deployment-and-serving/) -->\n",
    "\n",
    "- [ML infrastructure tools for ML monitoring and observability](https://arize.com/ml-infrastructure-tools-ml-observability/)\n",
    "\n",
    "Visit the [Arize Blog](https://arize.com/blog) and [Resource Center](https://arize.com/resource-hub/) for more resources on ML observability and model monitoring.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
