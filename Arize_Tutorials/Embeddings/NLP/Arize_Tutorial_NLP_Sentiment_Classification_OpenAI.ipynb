{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1efe50e",
   "metadata": {
    "id": "a1efe50e"
   },
   "source": [
    "<center><img src=\"https://storage.googleapis.com/arize-assets/arize-logo-white.jpg\" width=\"200\"/></center>\n",
    "\n",
    "# <center>Getting Started with the Arize Platform</center>\n",
    "## <center> Investigating Embedding Drift in NLP: Sentiment Classification</center>\n",
    "\n",
    "**In this walkthrough, we are going to ingest embedding data and look at embedding drift.** \n",
    "\n",
    "In this scenario, you are in charge of maintaining a sentiment classification model. This simple model takes online reviews of your U.S.-based product as the input and predict whether the reviewer's sentiment was positive, negative, or neutral. You trained your sentiment classification model on English reviews. However, once the model was released into production, you notice that the performance of the model has degraded over a period of time.\n",
    "\n",
    "Arize is able to surface the reason for this performance degradation. In this example, the presence of reviews written in Spanish impact the model's performance. You can surface and troubleshoot this issue by analyzing the _embedding vectors_ associated with the online review text.\n",
    "\n",
    "It is worth noting that, according to our research, inspecting embedding drift can surface problems with your data before they cause performance degradation.\n",
    "\n",
    "In this tutorial, we will start from scratch. We will:\n",
    "* Download the data\n",
    "* Obtain embedding vectors using OpenAI's API\n",
    "* Train the model\n",
    "* Obtain predictions\n",
    "* Log the inferences into the Arize Platform\n",
    "\n",
    "We will be using [OpenAI](https://openai.com/)'s API to make this process extremely easy. The OpenAI API can be applied to virtually any task that involves understanding or generating natural language, offering a wide variety of models for different applications, from content generation to semantic search and classification.\n",
    "\n",
    "In this tutorial we will be leveraging OpenAI's tools to generate embedding representations of the input text. Next, we will train a simple `RandomForestClassifier` to classify the online reviews into the following classes: `Positive`, `Negative`, `Neutral`.\n",
    "\n",
    "**Note**: This example compares training vs production data. Arize supports sending only one dataset.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30463bd6",
   "metadata": {
    "id": "30463bd6"
   },
   "source": [
    "# Step 0. Setup and Getting the Data\n",
    "\n",
    "We will first install 🤗Hugging Face's `datasets` and OpenAI's `openai` libraries. In addition, we will install `umap-learn` for embedding visualization. \n",
    "\n",
    "We'll explain each of the imports below as we use them through this tutorial.\n",
    "\n",
    "\n",
    "## Install Dependencies and Import Libraries 📚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e028f2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q datasets umap-learn pyyaml==5.4.1 arize\n",
    "!pip install -q --upgrade openai\n",
    "\n",
    "import uuid\n",
    "import time\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from datasets import load_dataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from umap import UMAP\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from arize.pandas.logger import Client\n",
    "from arize.utils.types import Environments, ModelTypes, EmbeddingColumnNames, Schema\n",
    "\n",
    "import openai\n",
    "from openai.embeddings_utils import get_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef976bd",
   "metadata": {
    "id": "8ef976bd"
   },
   "source": [
    "## **🌐 Download the Data**\n",
    "\n",
    "The easiest way to load a dataset is from the [Hugging Face Hub](https://huggingface.co/datasets). There are already thousands of datasets in over 100 languages on the Hub. At Arize, we have crafted the [arize-ai/ecommerce_reviews_with_language_drift](https://huggingface.co/datasets/arize-ai/ecommerce_reviews_with_language_drift) dataset for this example notebook. \n",
    "\n",
    "Thanks to Hugging Face 🤗 Datasets, we can download the data in one line of code. The `Dataset` object comes equipped with methods that make it very easy to inspect, pre-process, and post-process your data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc750f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"arize-ai/ecommerce_reviews_with_language_drift\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adce6e91",
   "metadata": {
    "id": "adce6e91"
   },
   "source": [
    "You can select the splits of the dataset as you would in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f725d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, prod_ds = dataset['training'], dataset['production']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f02183c",
   "metadata": {
    "id": "6f02183c"
   },
   "source": [
    "## Inspect the Data\n",
    "\n",
    "It is often convenient to convert a Hugging Face `Dataset` object to a Pandas `DataFrame` so we can access high-level APIs for data visualization. To do so, the 🤗Datasets library provides a `set_format()` method that allows us to change the output format of the `Dataset`. This does not change the underlying data format, an Arrow table. When the `DataFrame` format is no longer needed, we can reset the output format using `reset_format()`.\n",
    "\n",
    "From this point forward, it is convenient to use Pandas DataFrames. We can do so easily using the format methods we have already seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed1b4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_ds.to_pandas()\n",
    "prod_df = prod_ds.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe79661f",
   "metadata": {
    "id": "fe79661f"
   },
   "source": [
    "To stay within the limits of OpenAI's free tier account, we will sample our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4da427",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.sample(200, ignore_index=True)\n",
    "prod_df = prod_df.sample(500, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330a3f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472ba02f",
   "metadata": {
    "id": "472ba02f"
   },
   "source": [
    "# Step 1. Developing your Sentiment Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4418b51c",
   "metadata": {
    "id": "4418b51c"
   },
   "source": [
    "## Obtain text embeddings\n",
    "\n",
    "The OpenAI Python library provides convenient access to the OpenAI API. We use the `get_embedding` function to generate an embedding vector from a piece of text - making use of one of the pre-trained models from OpenAI.\n",
    "\n",
    "They offer three families of embedding models for different functionalities: text search, text similarity and code search. Each family includes up to four models on a spectrum of capability\n",
    "\n",
    "* Ada (1024 dimensions),\n",
    "* Babbage (2048 dimensions),\n",
    "* Curie (4096 dimensions),\n",
    "* Davinci (12288 dimensions).\n",
    "\n",
    "Given that our usecase is sentiment classification, we will use the pre-trained model `text-similarity-babbage-001`.\n",
    "\n",
    "To use OpenAI's tools, create a free account [here](https://openai.com/api/). Then, find your `API_KEY` by clicking on your profile icon and into \"View API Keys\". If you logged in as part of an organization, you'll need to enter your organization's api key as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5134ad4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORGANIZATION_KEY = \"OPENAI_ORG_KEY\"\n",
    "API_KEY = \"OPENAI_API_KEY\"\n",
    "if API_KEY == \"OPENAI_API_KEY\":\n",
    "    raise ValueError(\"❌ CHANGE OPENAI's API_KEY\")\n",
    "\n",
    "openai.api_key = API_KEY\n",
    "if ORGANIZATION_KEY != \"OPENAI_ORG_KEY\":\n",
    "    openai.organization = ORGANIZATION_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xD1-W-LCfElW",
   "metadata": {
    "id": "xD1-W-LCfElW"
   },
   "source": [
    "OpenAI's free tier account has limitations on their usage. We have prepared the following function for you to use their embedding model at the allowed free rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51404e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_from_series(series, max_rate=60):\n",
    "    emb_series = series.copy()\n",
    "    N = np.ceil(len(series)/max_rate).astype(int)\n",
    "    for i in range(N):\n",
    "        start = i*max_rate\n",
    "        end = (i+1)*max_rate\n",
    "        if end>len(series):\n",
    "            end = len(series)\n",
    "        \n",
    "        emb_series[start:end] = series[start:end].apply(lambda x: get_embedding(x, engine='text-similarity-babbage-001'))\n",
    "        time.sleep(60)\n",
    "    return emb_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "juXKamJ9fZS1",
   "metadata": {
    "id": "juXKamJ9fZS1"
   },
   "source": [
    "Finally, we now use the aforementioned `get_embeddings_from_series` function to obtain the embedding vectors of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cb3025",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['text_vector'] = get_embeddings_from_series(train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04679a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_df['text_vector'] = get_embeddings_from_series(prod_df['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb06f84",
   "metadata": {
    "id": "6eb06f84"
   },
   "source": [
    "## Inspect text embeddings\n",
    "\n",
    "We can do a quick inspection of how the embedding vectors obtained for our training set look using [UMAP](https://umap-learn.readthedocs.io/en/latest/). When using Arize, you will get this view automatically so you won't have to do this with your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1595b0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_embeddings(X,y):\n",
    "    projections = UMAP().fit_transform(X)\n",
    "    \n",
    "    df_emb = pd.DataFrame({})\n",
    "    df_emb[\"X\"] = projections[:,0]\n",
    "    df_emb[\"Y\"] = projections[:,1]\n",
    "    df_emb['label'] = y_train\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(7,3))\n",
    "    axes = axes.flatten()\n",
    "    cmaps = [\"Reds\",\"Greys\",\"Greens\"]\n",
    "    labels = train_ds.features[\"label\"].names\n",
    "\n",
    "    for i, (label, cmap) in enumerate(zip(labels, cmaps)):\n",
    "        df_emb_sub = df_emb.query(f\"label=={i}\")\n",
    "        axes[i].hexbin(df_emb_sub[\"X\"], df_emb_sub[\"Y\"], cmap=cmap, gridsize=20, linewidths=(0,))\n",
    "        axes[i].set_title(label)\n",
    "        axes[i].set_xticks([])\n",
    "        axes[i].set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b261ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_embeddings(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "y09jsd2nf-5e",
   "metadata": {
    "id": "y09jsd2nf-5e"
   },
   "source": [
    "The pre-trained model from OpenAI is able to extract embedding vectors that are different depending on the label values, without ever seeing the data or being trained on it!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737b3bae",
   "metadata": {
    "id": "737b3bae"
   },
   "source": [
    "## Train the model\n",
    "\n",
    "Now that we have used the pre-trained model to perform feature extraction and obtain embedding vectors, we can train a simple text sentiment classifier that uses the embedding vectors as features. We will use `RandomForestClassifier` from the [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed0d390",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "X_train, y_train = np.stack(train_df['text_vector']), np.stack(train_df['label'])\n",
    "X_prod, y_prod = np.stack(prod_df['text_vector']), np.stack(prod_df['label'])\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jPr_McjpiV8K",
   "metadata": {
    "id": "jPr_McjpiV8K"
   },
   "source": [
    "## Evaluate the model\n",
    "\n",
    "Let's evaluate the performance of the model on our validation and production sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86dc516",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_val = clf.predict(X_val)\n",
    "\n",
    "report = classification_report(y_val, preds_val)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce656748",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_prod = clf.predict(X_prod)\n",
    "\n",
    "report = classification_report(y_prod, preds_prod)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qcuh1SqWibeh",
   "metadata": {
    "id": "qcuh1SqWibeh"
   },
   "source": [
    "Something is happening with our data that causes production performance degradation. Let's use Arize to identify the issue and troubleshoot.Something is happening with our data that causes our production performance degradation. Let's use Arize to identify the issue and troubleshoot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e6edc1",
   "metadata": {
    "id": "49e6edc1"
   },
   "source": [
    "# Step 2. Prepare your data to be sent to Arize\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5decc2",
   "metadata": {
    "id": "7c5decc2"
   },
   "source": [
    "## Update the timestamps\n",
    "\n",
    "The data that you are working with was constructed in April of 2022. Hence, we will update the timestamps so they are current at the time that you're sending data to Arize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a94ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['prediction_ts'] = (train_df['prediction_ts']/4).astype(float)\n",
    "prod_df['prediction_ts'] = (prod_df['prediction_ts']/4).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1a5d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_ts = max(prod_df['prediction_ts'])\n",
    "now_ts = datetime.timestamp(datetime.now())\n",
    "delta_ts = now_ts - last_ts    \n",
    "\n",
    "train_df['prediction_ts'] = (train_df['prediction_ts'] + delta_ts).astype(float)\n",
    "prod_df['prediction_ts'] = (prod_df['prediction_ts'] + delta_ts).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e0d97e",
   "metadata": {
    "id": "92e0d97e"
   },
   "source": [
    "## Map labels to class names\n",
    "\n",
    "For readability, we will want to log our inferences (predictions and actuals) with class labels instead of numeric labels. Since we used Hugging Face 🤗 Datasets to download our dataset, it already comes equipped with methods to do this.\n",
    "\n",
    "The dataset we downloaded defined the label to be an instance of the `datasets.ClassLabel` class, which has the convenient method `int2str` (visit [Hugging Face documentation](https://huggingface.co/docs/datasets/v2.2.1/en/package_reference/main_classes#datasets.ClassLabel.names) for more information)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb856f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_int2str(row):\n",
    "    return train_ds.features['label'].int2str(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c040e8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['label'] = train_df['label'].apply(label_int2str)\n",
    "prod_df['label'] = prod_df['label'].apply(label_int2str)\n",
    "\n",
    "train_df['pred_label'] = train_df['pred_label'].apply(label_int2str)\n",
    "prod_df['pred_label'] = prod_df['pred_label'].apply(label_int2str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787e19d2",
   "metadata": {
    "id": "787e19d2"
   },
   "source": [
    "## Add prediction ids\n",
    "\n",
    "The Arize platform uses prediction IDs to link a prediction to an actual. Visit the [Arize documentation](https://docs.arize.com/arize/data-ingestion/model-schema/5.-prediction-id?q=prediction_id) for more details.\n",
    "\n",
    "You can generate prediction IDs as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a3df9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_prediction_id(df):\n",
    "    return [str(uuid.uuid4()) for _ in range(df.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daf125d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['prediction_id'] = add_prediction_id(train_df)\n",
    "prod_df['prediction_id'] = add_prediction_id(prod_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9788542",
   "metadata": {
    "id": "a9788542"
   },
   "source": [
    "# Step 3. Sending Data into Arize 💫\n",
    "\n",
    "## Select the columns we want to send to Arize (optional)\n",
    "\n",
    "This step is not really necessary, since we will select the columns we want to send to Arize using the `Schema` definition (below). However, for the purpose of visibility, this is our final `DataFrame` with the data that will be sent to Arize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30903903",
   "metadata": {},
   "outputs": [],
   "source": [
    "arize_columns = [\n",
    "    'prediction_id', \n",
    "    'prediction_ts', \n",
    "    'reviewer_age', \n",
    "    'reviewer_gender', \n",
    "    'product_category', \n",
    "    'language',\n",
    "    'text',\n",
    "    'text_vector',\n",
    "    'label',\n",
    "    'pred_label'\n",
    "    ]\n",
    "\n",
    "train_df = train_df[arize_columns]\n",
    "prod_df = prod_df[arize_columns]\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64888650",
   "metadata": {
    "id": "64888650"
   },
   "source": [
    "## Import and Setup Arize Client\n",
    "\n",
    "The first step is to setup the Arize client. After that we will log the data.\n",
    "\n",
    "Copy the Arize `API_KEY` and `SPACE_ID` from your Space Settings page (shown below) to the variables in the cell below. We will also be setting up some metadata to use across all logging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61f22ff",
   "metadata": {
    "id": "b61f22ff"
   },
   "source": [
    "<img src=\"https://storage.googleapis.com/arize-assets/fixtures/copy-id-and-key.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ef3e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPACE_ID = \"SPACE_ID\"\n",
    "API_KEY = \"API_KEY\"\n",
    "arize_client = Client(space_id=SPACE_ID, api_key=API_KEY)\n",
    "model_id = \"NLP-demo-openai-sentiment-classification-language-drift\"\n",
    "model_version = \"1.0\"\n",
    "model_type = ModelTypes.SCORE_CATEGORICAL\n",
    "if SPACE_ID == \"SPACE_ID\" or API_KEY == \"API_KEY\":\n",
    "    raise ValueError(\"❌ CHANGE SPACE_ID AND/OR API_KEY\")\n",
    "else:\n",
    "    print(\"✅ Import and Setup Arize Client Done! Now we can start using Arize!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73be3c2a",
   "metadata": {
    "id": "73be3c2a"
   },
   "source": [
    "Now that the Arize client is setup, let's go ahead and log all of our data to the platform. For more details on how **`arize.pandas.logger`** works, visit our documentation.\n",
    "\n",
    "[![Buttons_OpenOrange.png](https://storage.googleapis.com/arize-assets/fixtures/Buttons_OpenOrange.png)](https://docs.arize.com/arize/sdks-and-integrations/python-sdk/arize.pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f73822",
   "metadata": {
    "id": "50f73822"
   },
   "source": [
    "## Define the Schema \n",
    "\n",
    "A Schema instance specifies the column names for corresponding data in the dataframe. While we could define different Schemas for training and production datasets, the dataframes have the same column names, so the Schema will be the same in this instance.\n",
    "\n",
    "To ingest non-embedding features, it suffices to provide a list of column names that contain the features in our dataframe. Embedding features, however, are a little bit different.\n",
    "\n",
    "Arize allows you to ingest not only the embedding vector, but the raw data associtated with that embedding, or a URL link to that raw data. Therefore, up to 3 columns can be associated to the same _embedding object_*. To be able to do this, Arize's SDK provides the `EmbeddingColumnNames` class, used below.\n",
    "\n",
    "*NOTE: This is how we refer to the 3 possible pieces of information that can be sent as embedding objects:\n",
    "* Embedding `vector` (required)\n",
    "* Embedding `data` (optional): raw text associated with the embedding vector\n",
    "* Embedding `link_to_data` (optional): link to the data file (image, audio, ...) associated with the embedding vector\n",
    "\n",
    "Learn more [here](https://docs.arize.com/arize/sending-data/model-schema-reference#8.-embedding-features-unstructured)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3dc8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'reviewer_age',\n",
    "    'reviewer_gender',\n",
    "    'product_category',\n",
    "    'language',\n",
    "]\n",
    "\n",
    "embedding_features = {\n",
    "    # Dictionary keys will be the displayed name of the embedding feature in the app\n",
    "    \"text_embedding\": EmbeddingColumnNames(\n",
    "        vector_column_name=\"text_vector\",\n",
    "        data_column_name=\"text\",\n",
    "    ),\n",
    "    \n",
    "}\n",
    "\n",
    "# Define a Schema() object for Arize to pick up data from the correct columns for logging\n",
    "schema = Schema(\n",
    "    prediction_id_column_name=\"prediction_id\",\n",
    "    timestamp_column_name=\"prediction_ts\",\n",
    "    prediction_label_column_name=\"pred_label\",\n",
    "    actual_label_column_name=\"label\",\n",
    "    feature_column_names=features,\n",
    "    embedding_feature_column_names=embedding_features\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9fe66a",
   "metadata": {
    "id": "3c9fe66a"
   },
   "source": [
    "## Log Training Data\n",
    "\n",
    "**Note**: This example compares training vs production data. Arize supports sending only one dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14abb439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging Training DataFrame\n",
    "response = arize_client.log(\n",
    "    dataframe=train_df,\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    model_type=model_type,\n",
    "    environment=Environments.TRAINING,\n",
    "    schema=schema\n",
    ")\n",
    "\n",
    "\n",
    "# If successful, the server will return a status_code of 200\n",
    "if response.status_code != 200:\n",
    "    print(f\"❌ logging failed with response code {response.status_code}, {response.text}\")\n",
    "else:\n",
    "    print(f\"✅ You have successfully logged training set to Arize\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaafe1f",
   "metadata": {
    "id": "ccaafe1f"
   },
   "source": [
    "## Log Production Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd98af0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging Production DataFrame\n",
    "response = arize_client.log(\n",
    "    dataframe=prod_df,\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    model_type=model_type,\n",
    "    environment=Environments.PRODUCTION,\n",
    "    schema=schema\n",
    ")\n",
    "\n",
    "if response.status_code != 200:\n",
    "    print(f\"❌ logging failed with response code {response.status_code}, {response.text}\")\n",
    "else:\n",
    "    print(f\"✅ You have successfully logged production set to Arize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8620063c",
   "metadata": {
    "id": "8620063c"
   },
   "source": [
    "# Step 5. Confirm Data in Arize ✅\n",
    "Note that the Arize platform takes about 15 minutes to index embedding data. While the model should appear immediately, the data will not show up until the indexing is complete. Feel free to head over to the **Data Ingestion** tab for your model to watch Arize works its magic!🔮\n",
    "\n",
    "You will be able to see the predictions, actuals, and feature importances that have been sent in the last 30 minutes, last day or last week.\n",
    "\n",
    "An example view of the Data Ingestion tab from a model, when data is sent continuously over 30 minutes, is shown in the image below.\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/arize-assets/fixtures/data-ingestion-tab.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d1b93b",
   "metadata": {
    "id": "a2d1b93b"
   },
   "source": [
    "# Check the Embedding Data in Arize\n",
    "\n",
    "First, set the baseline to the training set that we logged before.\n",
    "\n",
    "<img src=\"https://storage.cloud.google.com/arize-assets/fixtures/embedding_setup_baseline.gif\" width=\"700\">\n",
    "\n",
    "\n",
    "If your model contains embedding data, you will see it in your Model's Overview page. \n",
    "\n",
    "<img src=\"https://storage.cloud.google.com/arize-assets/fixtures/Embeddings/NLP/NLP-reviews-demo-language-drift-overview.jpg\" width=\"700\">\n",
    "\n",
    " Click on the Embedding Name or the Euclidean Distance value to see how your embedding data is drifting over time. In the picture below we represent the global euclidean distance between your production set (at different points in time) and the baseline (which we set to be our training set). We can see there is a period of a week where suddenly the distance is remarkably higher. This shows us that during that time text data was sent to our model that was different than what it was trained on (English). This is the period of time when reviews written in Spanish were sent alongside the expected English reviews.\n",
    " \n",
    "<img src=\"https://storage.cloud.google.com/arize-assets/fixtures/Embeddings/NLP/NLP-reviews-demo-language-drift-emb-0.jpg\" width=\"700\">\n",
    "\n",
    "In addition to the drift tracking plot above, below you can find the UMAP visualization of your data, according to the point in time selected. Notice that the production data and our baseline (training) data are superimposed, which is indicative that the model is seeing data in production similar to the data it was trained on.\n",
    "\n",
    "<img src=\"https://storage.cloud.google.com/arize-assets/fixtures/Embeddings/NLP/NLP-reviews-demo-language-drift-emb-1.jpg\" width=\"700\">\n",
    "\n",
    "Next, select a point in time when the drift was high and select a UMAP visualization in 2D. We can see that both training and production data are superimposed for the most part, but another cluster of production data has appeared. This indicates that the model is seeing data in production qualitatively different to the data it was trained on, and in this case causing performance degradation.\n",
    "\n",
    "<img src=\"https://storage.cloud.google.com/arize-assets/fixtures/Embeddings/NLP/NLP-reviews-demo-language-drift-emb-2.jpg\" width=\"700\">\n",
    "\n",
    "For further inspection, you may select a 3D UMAP view and clicked _Explore UMAP_ to expand the view. With this view we can interact in 3D with our dataset. We can zoom, rotate, and drag so we can see the areas of our dataset that are most interesting to us. Check out the workflow below:\n",
    "\n",
    "<img src=\"https://storage.cloud.google.com/arize-assets/fixtures/Embeddings/NLP/NLP-reviews-demo-language-drift-workflow.gif\" width=\"700\">\n",
    "\n",
    "In the display above, Arize offers many coloring options:\n",
    "1. By Dataset: You can see that the coloring has been made to distinguish production data vs baseline data (training in this example). This is specifically useful to detect drift. In this example, we can see that there is some production data far away from any training data, giving an indication of severe dataset drift. We can identify exactly what datapoints our baseline is missing so that re-train effectively.\n",
    "2. By Prediction Label: This coloring option gives an insight on how is our model making decisions. Where are the different classes located in the space? Is the model predicting one class in regions where it should be predicting another?\n",
    "3. By Actual Label: This coloring option is great if we want to identify labeling issues. For instance, if inside the orange cloud, we can see a points of other colors, it is a good idea to check and see if the labels are wrong. Further we can use the corrected labels for re-training. This separation is specially difficult when clusters are joined, since both the model and UMAP have trouble separating the data-points.\n",
    "4. By Correctness: This coloring option offers a quick way of identifying where the bulk of your model's mistakes are placed, giving you an area to pay attention to. In this example, we can see that the spanish reviews are almost all red.\n",
    "5. By Confusion Matrix: This coloring option allows you to select a `positive class` and color the data-points as `True Positives`, `True Negatives`, `False Positives`, `False Negatives`.\n",
    "6. By Feature: You can identify areas of the space where your model might be underperforming and, by coloring the points by feature, identify patterns at feature level. In other words, you can identify a slice of your data sharing a common feature (or features) that are causing a problem.\n",
    "7. By Prediction Score: You can identify areas where your model is more confident of its predictions and areas where your model struggled more to make a decision.\n",
    "\n",
    "More coloring options will be added to help you understand and debug your model and dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9a381c",
   "metadata": {
    "id": "ef9a381c"
   },
   "source": [
    "# Wrap Up 🎁\n",
    "Congratulations, you've now sent your first machine learning embedding data to the Arize platform!!\n",
    "\n",
    "Additionally, if you want to remove this example model from your account, just click **Models** -> **NLP-reviews-demo-language-drift** -> **config** -> **delete**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a253cfb6",
   "metadata": {
    "id": "a253cfb6"
   },
   "source": [
    "### Overview\n",
    "Arize is an end-to-end ML observability and model monitoring platform. The platform is designed to help ML engineers and data science practitioners surface and fix issues with ML models in production faster with:\n",
    "- Automated ML monitoring and model monitoring\n",
    "- Workflows to troubleshoot model performance\n",
    "- Real-time visualizations for model performance monitoring, data quality monitoring, and drift monitoring\n",
    "- Model prediction cohort analysis\n",
    "- Pre-deployment model validation\n",
    "- Integrated model explainability\n",
    "\n",
    "### Website\n",
    "Visit Us At: https://arize.com/model-monitoring/\n",
    "\n",
    "### Additional Resources\n",
    "- [What is ML observability?](https://arize.com/what-is-ml-observability/)\n",
    "- [Monitor Unstructured Data with Arize](https://arize.com/blog/monitor-unstructured-data-with-arize)\n",
    "- [Getting Started With Embeddings Is Easier Than You Think](https://arize.com/blog/getting-started-with-embeddings-is-easier-than-you-think)\n",
    "- [Playbook to model monitoring in production](https://arize.com/the-playbook-to-monitor-your-models-performance-in-production/)\n",
    "- [Using statistical distance metrics for ML monitoring and observability](https://arize.com/using-statistical-distance-metrics-for-machine-learning-observability/)\n",
    "<!-- - [ML infrastructure tools for data preparation](https://arize.com/ml-infrastructure-tools-for-data-preparation/) -->\n",
    "- [ML infrastructure tools for model building](https://arize.com/ml-infrastructure-tools-for-model-building/)\n",
    "- [ML infrastructure tools for production](https://arize.com/ml-infrastructure-tools-for-production-part-1/)\n",
    "<!-- - [ML infrastructure tools for model deployment and model serving](https://arize.com/ml-infrastructure-tools-for-production-part-2-model-deployment-and-serving/) -->\n",
    "\n",
    "- [ML infrastructure tools for ML monitoring and observability](https://arize.com/ml-infrastructure-tools-ml-observability/)\n",
    "\n",
    "Visit the [Arize Blog](https://arize.com/blog) and [Resource Center](https://arize.com/resource-hub/) for more resources on ML observability and model monitoring.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
