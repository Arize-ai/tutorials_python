{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQj9YRzkS9St"
   },
   "source": [
    "# Tutorial: Sending PySpark DataFrame to Arize\n",
    "\n",
    "In the current version of Arize Python SDK, only Pandas DataFrames are supported. To log Spark DataFrames, which have `rdds` as their underlying structure, we will use `mapInPandas` to log them to arize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EjTwoaJ_GzbZ"
   },
   "source": [
    "# Install Dependencies in Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pyspark\n",
    "!pip install -q arize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ldVoUMYSVKbF"
   },
   "source": [
    "# Parallelizing PySpark DataFrame\n",
    "We first create a dummy PySpark DataFrame to send.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import Row, SparkSession\n",
    "import pandas as pd\n",
    "import uuid\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Read some dummy data for logging to Arize later\n",
    "data = pd.read_csv(\n",
    "    \"https://storage.googleapis.com/arize-assets/fixtures/compare-model-a.csv\"\n",
    ")\n",
    "df_pandas = data[\n",
    "    [\"loan_amount\", \"interest_rate\", \"grade\", \"prediction\", \"score\"]\n",
    "]\n",
    "\n",
    "# create many rows with UUID\n",
    "df_pandas = pd.concat([df_pandas] * 5)\n",
    "df_pandas[\"prediction_id\"] = [uuid.uuid4() for _ in range(len(df_pandas.index))]\n",
    "df_pandas = df_pandas.astype(\n",
    "    {\"grade\": \"string\", \"prediction\": \"string\", \"prediction_id\": \"string\"}\n",
    ")\n",
    "\n",
    "print(\"This is a pandas DataFrame:\")\n",
    "display(df_pandas)\n",
    "\n",
    "# # Create PySpark dataframe unparallelized\n",
    "df_spark = spark.createDataFrame(df_pandas)\n",
    "\n",
    "\n",
    "# print(\"\\nThis is the corresponding spark DataFrame\")\n",
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7vQo-N3cggh"
   },
   "source": [
    "# Using `mapInPandas` to log each partition to Arize\n",
    "`mapInPandas`, maps an iterator of batches in the current DataFrame using a Python native function that takes and outputs a pandas DataFrame, and returns the result as a DataFrame.\n",
    "\n",
    "The function should take an iterator of pandas.DataFrames and return another iterator of pandas.DataFrames. All columns are passed together as an iterator of pandas.DataFrames to the function and the returned iterator of pandas.DataFrames are combined as a DataFrame. Each pandas.DataFrame size can be controlled by spark.sql.execution.arrow.maxRecordsPerBatch.\n",
    "\n",
    "We should send `spark_df` to Arize with at least one of: `shap, prediction_labels, actual_labels`\n",
    "\n",
    "## How To Log to Arize:\n",
    "\n",
    "You will need to update the `API_KEY` and `SPACE_ID`\n",
    "### Setting up Arize Client:\n",
    "First, copy the Arize `API_KEY` and `SPACE_ID` from your Space Settings page linked below!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/arize-assets/fixtures/copy-id-and-key.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arize.pandas.logger import Client, Schema\n",
    "from arize.utils.types import ModelTypes, Environments\n",
    "\n",
    "SPACE_ID = \"SPACE_ID\"\n",
    "API_KEY = \"API_KEY\"\n",
    "arize_client = Client(space_id=SPACE_ID, api_key=API_KEY)\n",
    "\n",
    "if SPACE_ID == \"SPACE_ID\" or API_KEY == \"API_KEY\":\n",
    "    raise ValueError(\"‚ùå CHANGE SPACE_ID AND/OR API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iTVAA--tKdrL"
   },
   "source": [
    "# Define Logging Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import uuid\n",
    "import time\n",
    "\n",
    "\n",
    "# Pandas transformation function returning pandas dataframe\n",
    "def log_to_arize(dfs):\n",
    "    for df in dfs:\n",
    "        pandas_df_schema = Schema(\n",
    "            prediction_id_column_name=\"prediction_id\",  # REQUIRED\n",
    "            prediction_label_column_name=\"prediction\",\n",
    "            prediction_score_column_name=\"score\",\n",
    "            feature_column_names=[\"loan_amount\", \"interest_rate\", \"grade\"],\n",
    "        )\n",
    "\n",
    "        # Step 3: Log to arize, if response not 200, wait 10 second and try again, max retry 10 times\n",
    "        max_tries = 10\n",
    "        for i in range(max_tries):\n",
    "            response = arize_client.log(\n",
    "                dataframe=df,\n",
    "                schema=pandas_df_schema,\n",
    "                model_id=\"pyspark-loan-model\",\n",
    "                model_version=\"1.0\",\n",
    "                model_type=ModelTypes.SCORE_CATEGORICAL,\n",
    "                environment=Environments.PRODUCTION,\n",
    "            )\n",
    "\n",
    "            if response.status_code != 200:\n",
    "                time.sleep(10)\n",
    "            else:\n",
    "                yield df\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x9LQq2PujitJ"
   },
   "source": [
    "# Logging Example\n",
    "Here we will take our spark dataframe and apply the `mapInPandas` method, with input args being our `log_to_arize` function, and specifying our spark shcema. We apply the `count` method to make enforce the entire spark dataframe is iterated over.\n",
    "\n",
    "You should see your inference count that was sent to the Arize Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark.mapInPandas(log_to_arize, df_spark.schema).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TjezXxbOWcjY"
   },
   "source": [
    "# **Overview**\n",
    "\n",
    "\n",
    "Arize is an end-to-end ML observability and model monitoring platform. The platform is designed to help ML engineers and data science practitioners surface and fix issues with ML models in production faster with:\n",
    "- Automated ML monitoring and model monitoring\n",
    "- Workflows to troubleshoot model performance\n",
    "- Real-time visualizations for model performance monitoring, data quality monitoring, and drift monitoring\n",
    "- Model prediction cohort analysis\n",
    "- Pre-deployment model validation\n",
    "- Integrated model explainability\n",
    "\n",
    "### Website\n",
    "Visit Us At: https://arize.com/model-monitoring/\n",
    "\n",
    "### Additional Resources\n",
    "- [What is ML observability?](https://arize.com/what-is-ml-observability/)\n",
    "- [Playbook to model monitoring in production](https://arize.com/the-playbook-to-monitor-your-models-performance-in-production/)\n",
    "- [Using statistical distance metrics for ML monitoring and observability](https://arize.com/using-statistical-distance-metrics-for-machine-learning-observability/)\n",
    "- [ML infrastructure tools for data preparation](https://arize.com/ml-infrastructure-tools-for-data-preparation/)\n",
    "- [ML infrastructure tools for model building](https://arize.com/ml-infrastructure-tools-for-model-building/)\n",
    "- [ML infrastructure tools for production](https://arize.com/ml-infrastructure-tools-for-production-part-1/)\n",
    "- [ML infrastructure tools for model deployment and model serving](https://arize.com/ml-infrastructure-tools-for-production-part-2-model-deployment-and-serving/)\n",
    "- [ML infrastructure tools for ML monitoring and observability](https://arize.com/ml-infrastructure-tools-ml-observability/)\n",
    "\n",
    "Visit the [Arize Blog](https://arize.com/blog) and [Resource Center](https://arize.com/resource-hub/) for more resources on ML observability and model monitoring.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
