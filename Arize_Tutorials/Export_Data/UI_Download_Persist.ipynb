{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yZkuNcfyq9C2"
   },
   "source": [
    "# Debugging and Analyzing Data from Arize Platform\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t0FsAoeIBv5A"
   },
   "source": [
    "Use this template to explore, analyze, and debug using data from the Arize platform. It takes in the data export URL, which you enter below, and produces a clean pandas dataframe that can be used for analysis.\n",
    "\n",
    "\n",
    " ***Note: Make a copy of this notebook to allow edits***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZURhR9oAvZRP"
   },
   "source": [
    "## Setting up the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JX5evpkLfx5B"
   },
   "source": [
    "Import libraries and define some helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import hashlib\n",
    "import os\n",
    "\n",
    "def get_value_from_dict(single_item_dict):\n",
    "    if len(single_item_dict) > 1:\n",
    "        print(\"FORMAT ERROR\")\n",
    "        print(single_item_dict)\n",
    "        return\n",
    "    return next(iter(single_item_dict.values()))\n",
    "\n",
    "def clean_up_dict_values(dict_to_clean):\n",
    "    for key in dict_to_clean:\n",
    "        if type(dict_to_clean[key]) == dict:\n",
    "            dict_to_clean[key] = get_value_from_dict(dict_to_clean[key])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AFcCCWHUr5Lc"
   },
   "source": [
    "**Edit paramaters** with your export url and desired file preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the URL to your file (provided by Arize) here\n",
    "arize_ui_url = 'YOUR_DATA_EXPORT_URL'\n",
    "#Edit persist Gdrive flag, helpful if running over multiple days\n",
    "persist_g_drive = True\n",
    "#If Gdrive Persist is true use this directory\n",
    "colab_persist_data_dir = \"/content/gdrive/MyDrive/colab_tmp_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R76je4iYsLiZ"
   },
   "source": [
    "Retrieve data from either the url or locally (if stored). Follow prompt instructions for authorization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_file_dir = \"./\"\n",
    "#Create a hash name to store locally\n",
    "#Hash file name is unique based on the URL\n",
    "file_hash = str(int(hashlib.sha1(arize_ui_url.encode(\"utf-8\")).hexdigest(), 16) % (10 ** 8))\n",
    "file_name = file_hash + \".json\"\n",
    "\n",
    "#Check if persisted / default don't use gdrive\n",
    "if persist_g_drive:\n",
    "  print('Persist Gdrive Flag = True')\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/gdrive', force_remount=True)\n",
    "  file_in_gdrive = colab_persist_data_dir +  file_name\n",
    "  if  os.path.isfile(file_in_gdrive):\n",
    "    print('Copying from persisted file in GDrive')\n",
    "    print(file_in_gdrive)\n",
    "    !cp $file_in_gdrive \".\"\n",
    "else:\n",
    "  print('Persist Gdrive Flag = False')\n",
    "\n",
    "#Download file from URL If not available locally\n",
    "if not os.path.isfile(local_file_dir + \"/\" + file_name):\n",
    "    print('Downloading File')\n",
    "    urllib.request.urlretrieve(arize_ui_url,local_file_dir + \"/\" + file_name)\n",
    "\n",
    "#Persist this file to Drive if flag is true, this will store file over multiple\n",
    "#runs of colab over a number of days\n",
    "if persist_g_drive:\n",
    "  if  not os.path.isfile(file_in_gdrive):\n",
    "    print('Persisting file in Gdrive')\n",
    "    full_file = local_file_dir + \"/\" + file_name\n",
    "    print('File: ' + full_file)\n",
    "    print('Gdrive Dir: ' + colab_persist_data_dir)\n",
    "    !cp  $full_file $colab_persist_data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tTOPB8gjtl4i"
   },
   "source": [
    "Set up dataframe with the exported data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct the formatted dataframe in this dictionary\n",
    "data_frame_dict = {}\n",
    "\n",
    "#open up the json file\n",
    "with open(local_file_dir + \"/\" + file_name) as fp:\n",
    "\n",
    "  # read the data point into a dictionary\n",
    "  line = fp.readline()\n",
    "  index = 0\n",
    "\n",
    "  while line:\n",
    "\n",
    "    formatted_data_point = {}\n",
    "    data_point = json.loads(line)\n",
    "\n",
    "    prediction_dict = data_point[\"prediction\"]\n",
    "\n",
    "    formatted_data_point[\"timestamp\"] = prediction_dict[\"timestamp\"]\n",
    "    formatted_data_point[\"modelVersion\"] = prediction_dict[\"modelVersion\"]\n",
    "    formatted_data_point[\"predictionId\"] = data_point[\"predictionId\"]\n",
    "\n",
    "\n",
    "    #features\n",
    "    features = prediction_dict[\"features\"]\n",
    "    clean_up_dict_values(features)\n",
    "    for k in features:\n",
    "      formatted_data_point[k] = features[k]\n",
    "\n",
    "    #prediction\n",
    "    del prediction_dict[\"features\"]\n",
    "    # score categorical models are structured differently\n",
    "    if (\"scoreCategorical\" in prediction_dict[\"label\"]):\n",
    "      if (\"score\" in prediction_dict[\"label\"][\"scoreCategorical\"]):\n",
    "        score = prediction_dict[\"label\"][\"scoreCategorical\"][\"score\"]\n",
    "      else:\n",
    "        score = None\n",
    "      prediction = prediction_dict[\"label\"][\"scoreCategorical\"][\"categorical\"]\n",
    "      formatted_data_point[\"score\"] = score\n",
    "      formatted_data_point[\"prediction\"] = prediction\n",
    "    else:\n",
    "      clean_up_dict_values(prediction_dict)\n",
    "      prediction = prediction_dict[\"label\"]\n",
    "      formatted_data_point[\"prediction\"] = prediction\n",
    "\n",
    "    #actual\n",
    "    actual_dict = data_point[\"actual\"]\n",
    "    # score categorical models are structured differently\n",
    "    if (\"scoreCategorical\" in actual_dict[\"label\"]):\n",
    "      clean_up_dict_values(actual_dict[\"label\"])\n",
    "\n",
    "    clean_up_dict_values(actual_dict)\n",
    "    actual = actual_dict[\"label\"]\n",
    "    formatted_data_point[\"actual\"] = actual\n",
    "\n",
    "    #add to new dataframe dict\n",
    "    data_frame_dict[index] = formatted_data_point\n",
    "\n",
    "    line = line = fp.readline()\n",
    "    index += 1\n",
    "\n",
    "\n",
    "prediction_df = pd.DataFrame(data_frame_dict)\n",
    "prediction_df = prediction_df.transpose()\n",
    "#Clean up - type timestamp to correct column type\n",
    "prediction_df['timestamp'] = pd.to_datetime(prediction_df['timestamp'])\n",
    "prediction_df['date_string'] = prediction_df.timestamp.dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kD4gWEBehL8z"
   },
   "source": [
    "Now the data is ready to be explored. Take a look at how it's formatted in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JF_Hz0MRu6Bz"
   },
   "source": [
    "## Examples of breaking down the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GdBluY0Jvf_9"
   },
   "source": [
    "### Count of prediction and actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ability to look at mean of prediction and actuals\n",
    "#If you are slicing on features in the platform this gives some examples how to slice on the same feature\n",
    "\n",
    "# Note this will not work in classification models where the predictions are True/False\n",
    "\"\"\"\n",
    "print(prediction_df['actual'].mean())\n",
    "print(prediction_df[(prediction_df['modelVersion'] == '1.0') ]['prediction'].mean())\n",
    "print(prediction_df[(prediction_df['modelVersion'] == '1.0') & (prediction_df.date_string > \"2021-03-20\")]['prediction'].mean())\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nscbto78wuDW"
   },
   "source": [
    "### MSE and other metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note this will not work in classification models\n",
    "\"\"\"\n",
    "from sklearn.metrics import r2_score, mean_squared_error,mean_absolute_error\n",
    "print(mean_absolute_error(prediction_df['actual'], prediction_df['prediction']))\n",
    "slice_grade_3 = prediction_df[(prediction_df.date_string > \"2021-03-20\") ]\n",
    "print(mean_absolute_error(slice_grade_3['actual'], slice_grade_3['prediction']))\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xp8SCtn0yq5W"
   },
   "source": [
    "### Grouping data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group all the prediction data by the day they were made\n",
    "\"\"\"\n",
    "prediction_df.groupby(['date_string']).count()['prediction'].head()\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YxagsRorD3cB"
   },
   "source": [
    "## Workspace\n",
    "Expand this notebook as much as you need for your data digging needs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Overview\n",
    "Arize is an end-to-end ML observability and model monitoring platform. The platform is designed to help ML engineers and data science practitioners surface and fix issues with ML models in production faster with:\n",
    "- Automated ML monitoring and model monitoring\n",
    "- Workflows to troubleshoot model performance\n",
    "- Real-time visualizations for model performance monitoring, data quality monitoring, and drift monitoring\n",
    "- Model prediction cohort analysis\n",
    "- Pre-deployment model validation\n",
    "- Integrated model explainability\n",
    "\n",
    "### Website\n",
    "Visit Us At: https://arize.com/model-monitoring/\n",
    "\n",
    "### Additional Resources\n",
    "- [What is ML observability?](https://arize.com/what-is-ml-observability/)\n",
    "- [Playbook to model monitoring in production](https://arize.com/the-playbook-to-monitor-your-models-performance-in-production/)\n",
    "- [Using statistical distance metrics for ML monitoring and observability](https://arize.com/using-statistical-distance-metrics-for-machine-learning-observability/)\n",
    "- [ML infrastructure tools for data preparation](https://arize.com/ml-infrastructure-tools-for-data-preparation/)\n",
    "- [ML infrastructure tools for model building](https://arize.com/ml-infrastructure-tools-for-model-building/)\n",
    "- [ML infrastructure tools for production](https://arize.com/ml-infrastructure-tools-for-production-part-1/)\n",
    "- [ML infrastructure tools for model deployment and model serving](https://arize.com/ml-infrastructure-tools-for-production-part-2-model-deployment-and-serving/)\n",
    "- [ML infrastructure tools for ML monitoring and observability](https://arize.com/ml-infrastructure-tools-ml-observability/)\n",
    "\n",
    "Visit the [Arize Blog](https://arize.com/blog) and [Resource Center](https://arize.com/resource-hub/) for more resources on ML observability and model monitoring.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
